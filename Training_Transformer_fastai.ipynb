{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9c0021d-e7c6-4d38-8db7-4e5c4f7b7218",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import librosa\n",
    "import torchaudio as ta\n",
    "ta.set_audio_backend(\"sox_io\")\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd.profiler as profiler\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, BatchSampler, RandomSampler\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "import glob\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# from python_files.Noise_Reduction_Datagen_paths import Signal_Synthesis_DataGen\n",
    "# from python_files.unet_basic import Model\n",
    "\n",
    "import warnings\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "import warnings\n",
    "\n",
    "import gc\n",
    "\n",
    "from random import shuffle\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Dict, Union, Optional, Callable, Any\n",
    "\n",
    "from datasets import load_dataset, get_dataset_split_names\n",
    "import huggingface_hub\n",
    "\n",
    "# from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc0eb57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huggingface_hub.notebook_login()\n",
    "HF_DATASETS_CACHE_DIR = \"/mnt/nvme0n1p1/Cache/huggingface/datasets\"\n",
    "os.makedirs(HF_DATASETS_CACHE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ee6fe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes the Dataframe of Clean SPeech and Noise Speech and returns noise added speech along with Random SNR noise added, Also the clean speech signal is returned\n",
    "class SignalSynthesisDataset(Dataset):\n",
    "    def __init__(self, clean_df: pd.DataFrame, noise_df: pd.DataFrame, \\\n",
    "                noise_path: Union[str, Path], clean_path: Union[str, Path], \\\n",
    "                sample_time: int, sr: int=16000, noise_snr_range: List[int]=[-5, 15], \\\n",
    "                noise_snr_prob: float=0.5):\n",
    "        \n",
    "        self.clean_df = clean_df\n",
    "        self.noise_df = noise_df\n",
    "        self.noise_path = noise_path\n",
    "        self.clean_path = clean_path\n",
    "        self.sample_time = sample_time\n",
    "        self.sr = sr\n",
    "        self.noise_snr_range = noise_snr_range\n",
    "        self.noise_snr_prob = noise_snr_prob\n",
    "\n",
    "    def get_ids(self, idx):\n",
    "        signal_id = idx//len(self.noise_df)\n",
    "        noise_id = idx - signal_id * len(self.noise_df)\n",
    "\n",
    "        return signal_id, noise_id\n",
    "    \n",
    "    def get_signal(self, signal_id, df, path) -> Tuple[List[torch.Tensor], torch.Tensor]:\n",
    "        signal_name = df.iloc[signal_id][\"path\"]\n",
    "        signal_path = path / signal_name\n",
    "        signal, sr = ta.load(signal_path)\n",
    "        if sr != self.sr:\n",
    "            warnings.warn(\"Resampling the signal to 16KHz\")\n",
    "            signal = ta.transforms.Resample(sr, self.sr)(signal)\n",
    "        signal = signal[0]\n",
    "        return signal, sr\n",
    "    \n",
    "    def adjust_clean_signal_length(self, signal: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        final_len = int(self.sr * self.sample_time)\n",
    "        if len(signal) > final_len:\n",
    "            signal = signal[:final_len]\n",
    "        else:\n",
    "            \n",
    "            add_len = final_len - len(signal)\n",
    "            zeros_signal = torch.zeros(add_len)\n",
    "            signal = signal.numpy()\n",
    "            signal = np.append(signal, (zeros_signal))\n",
    "            signal = torch.from_numpy(signal)\n",
    "\n",
    "        return signal\n",
    "    \n",
    "    def adjust_noise_signal_length(self, signal: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        final_len = int(self.sr * self.sample_time)\n",
    "        if len(signal) > final_len:\n",
    "            signal = signal[:final_len]\n",
    "        else:\n",
    "            signal_buffer = np.zeros(final_len)\n",
    "            signa = signal.numpy()\n",
    "            for i in range(final_len//len(signal)):\n",
    "                signal_buffer[i*signal : (i+1)*signal] = signal\n",
    "            signal_buffer[(i+1)*signal:] = signal[:final_len - (i+1)*signal]\n",
    "            signal = torch.from_numpy(signal_buffer)\n",
    "\n",
    "        return signal\n",
    "\n",
    "    def get_mixed_signal(self, clean_signal: torch.Tensor, noise_signal: torch.Tensor, snr):\n",
    "        clean_signal_power = clean_signal.norm(2)\n",
    "        noise_signal_power = noise_signal.norm(2)\n",
    "\n",
    "        scale = snr * clean_signal_power / noise_signal_power\n",
    "        mixed_signal = (scale * clean_signal + noise_signal) / 2\n",
    "        return mixed_signal\n",
    "    \n",
    "    def signals_alchemy(self, signal_id, noise_id, snr):\n",
    "        \n",
    "        clean_signal, clean_sr = self.get_signal(signal_id, self.clean_df, self.clean_path)\n",
    "        noise_signal, noise_sr = self.get_signal(noise_id, self.noise_df, self.noise_path)\n",
    "        clean_signal = self.adjust_clean_signal_length(clean_signal)\n",
    "        noise_signal = self.adjust_noise_signal_length(noise_signal)\n",
    "\n",
    "        noise_signal = self.get_mixed_signal(clean_signal, noise_signal, snr)\n",
    "\n",
    "\n",
    "\n",
    "        return clean_signal, noise_signal\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) * len(self.noise_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        signal_id, noise_id = self.get_ids(idx)\n",
    "        snr = random.uniform(self.noise_snr_range[0], self.noise_snr_range[1])\n",
    "        clean_signal, noisy_signal = self.signals_alchemy(signal_id, noise_id, snr)\n",
    "\n",
    "        return clean_signal, noisy_signal\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3649d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(434983, 10)\n"
     ]
    }
   ],
   "source": [
    "CLEAN_SAMPLES_PATH = Path(\"/mnt/nvme1n1p2/vamsik1211/Data/git-repos/Noise-Reduction-Deep-Learning/dataset/dataset/cv-corpus-5.1-2020-06-22-Resampled/en/clips\")\n",
    "NOISE_SAMPLES_PATH = Path(\"/mnt/nvme1n1p2/vamsik1211/Data/git-repos/Noise-Reduction-Deep-Learning/dataset/dataset/UrbanSound8K-Resampled/all_files\")\n",
    "\n",
    "train_df = pd.read_csv(\"dataset/dataset/cv-corpus-5.1-2020-06-22-Resampled/en/train.tsv\", sep=\"\\t\")\n",
    "train_df = train_df[train_df[\"up_votes\"] > 1]\n",
    "train_df = train_df[train_df[\"segment\"] != 'Singleword Benchmark']\n",
    "train_df = train_df[train_df[\"down_votes\"] <= 1]\n",
    "\n",
    "\n",
    "test_df = pd.read_csv(\"dataset/dataset/cv-corpus-5.1-2020-06-22-Resampled/en/test.tsv\", sep=\"\\t\")\n",
    "test_df = test_df[test_df[\"up_votes\"] > 1]\n",
    "test_df = test_df[test_df[\"segment\"] != 'Singleword Benchmark']\n",
    "test_df = test_df[test_df[\"down_votes\"] < 3]\n",
    "\n",
    "\n",
    "sample_time = 5 # secs\n",
    "sample_rate = 16000\n",
    "noise_snr_range = [-5, 15]\n",
    "noise_snr_prob = 0.5\n",
    "\n",
    "print(train_df.shape)\n",
    "\n",
    "\n",
    "signal_synthesis_dataset = SignalSynthesisDataset(train_df, train_df, NOISE_SAMPLES_PATH, CLEAN_SAMPLES_PATH, sample_time, sample_rate, noise_snr_range, noise_snr_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc3eee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_synthesis_dataset.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54bf29c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export HF_HOME=\"/home/vamsik1211/Data/Cache/huggingface\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9da43c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset common_voice_13_0 (/mnt/nvme0n1p1/Cache/huggingface/datasets/mozilla-foundation___common_voice_13_0/en/13.0.0/22809012aac1fc9803eaffc44122e4149043748e93933935d5ea19898587e4d7)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"mozilla-foundation/common_voice_13_0\", \"en\", split=\"train\", streaming=False, cache_dir=HF_DATASETS_CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71eec1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sampler = RandomSampler(dataset, replacement=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8497565d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1615888923406601"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[183749][\"audio\"][\"array\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d8a4b55",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m std \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[39m# dataloader = DataLoader(dataset, batch_size=32, num_workers=12)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# batch_sampler = BatchSampler(RandomSampler(dataset), batch_size=32, drop_last=False)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m# dataloader = DataLoader(dataset, batch_sampler=batch_sampler)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[39mfor\u001b[39;00m signals \u001b[39min\u001b[39;00m tqdm(dataloader):\n\u001b[1;32m     10\u001b[0m     signal \u001b[39m=\u001b[39m signals[\u001b[39m\"\u001b[39m\u001b[39maudio\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     11\u001b[0m     \u001b[39m# mean += signal.mean().sum()\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[39m# std += signal.std().sum()\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "mean = 0.0\n",
    "std = 0.0\n",
    "\n",
    "# dataloader = DataLoader(dataset, batch_size=32, num_workers=12)\n",
    "# batch_sampler = BatchSampler(RandomSampler(dataset), batch_size=32, drop_last=False)\n",
    "# dataloader = DataLoader(dataset, batch_sampler=batch_sampler)\n",
    "\n",
    "\n",
    "for signals in tqdm(dataloader):\n",
    "    signal = signals[\"audio\"][\"array\"]\n",
    "    # mean += signal.mean().sum()\n",
    "    # std += signal.std().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e79339e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m        Dataset\n",
      "\u001b[0;31mString form:\u001b[0m\n",
      "Dataset({\n",
      "    features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
      "    num_rows: 4479\n",
      "})\n",
      "\u001b[0;31mLength:\u001b[0m      4479\n",
      "\u001b[0;31mFile:\u001b[0m        ~/Data/miniconda3/envs/kaggle-env/lib/python3.8/site-packages/datasets/arrow_dataset.py\n",
      "\u001b[0;31mDocstring:\u001b[0m   A Dataset backed by an Arrow table.\n"
     ]
    }
   ],
   "source": [
    "cv_13?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "892e74ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.sampler.RandomSampler at 0x7f2aeeb57bb0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f068c8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Data loader. Combines a dataset and a sampler, and provides an iterable over\n",
      "the given dataset.\n",
      "\n",
      "The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
      "iterable-style datasets with single- or multi-process loading, customizing\n",
      "loading order and optional automatic batching (collation) and memory pinning.\n",
      "\n",
      "See :py:mod:`torch.utils.data` documentation page for more details.\n",
      "\n",
      "Args:\n",
      "    dataset (Dataset): dataset from which to load the data.\n",
      "    batch_size (int, optional): how many samples per batch to load\n",
      "        (default: ``1``).\n",
      "    shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
      "        at every epoch (default: ``False``).\n",
      "    sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
      "        samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
      "        implemented. If specified, :attr:`shuffle` must not be specified.\n",
      "    batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
      "        returns a batch of indices at a time. Mutually exclusive with\n",
      "        :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
      "        and :attr:`drop_last`.\n",
      "    num_workers (int, optional): how many subprocesses to use for data\n",
      "        loading. ``0`` means that the data will be loaded in the main process.\n",
      "        (default: ``0``)\n",
      "    collate_fn (Callable, optional): merges a list of samples to form a\n",
      "        mini-batch of Tensor(s).  Used when using batched loading from a\n",
      "        map-style dataset.\n",
      "    pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
      "        into device/CUDA pinned memory before returning them.  If your data elements\n",
      "        are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
      "        see the example below.\n",
      "    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
      "        if the dataset size is not divisible by the batch size. If ``False`` and\n",
      "        the size of dataset is not divisible by the batch size, then the last batch\n",
      "        will be smaller. (default: ``False``)\n",
      "    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
      "        from workers. Should always be non-negative. (default: ``0``)\n",
      "    worker_init_fn (Callable, optional): If not ``None``, this will be called on each\n",
      "        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
      "        input, after seeding and before data loading. (default: ``None``)\n",
      "    generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
      "        by RandomSampler to generate random indexes and multiprocessing to generate\n",
      "        `base_seed` for workers. (default: ``None``)\n",
      "    prefetch_factor (int, optional, keyword-only arg): Number of batches loaded\n",
      "        in advance by each worker. ``2`` means there will be a total of\n",
      "        2 * num_workers batches prefetched across all workers. (default value depends\n",
      "        on the set value for num_workers. If value of num_workers=0 default is ``None``.\n",
      "        Otherwise if value of num_workers>0 default is ``2``).\n",
      "    persistent_workers (bool, optional): If ``True``, the data loader will not shutdown\n",
      "        the worker processes after a dataset has been consumed once. This allows to\n",
      "        maintain the workers `Dataset` instances alive. (default: ``False``)\n",
      "    pin_memory_device (str, optional): the data loader will copy Tensors\n",
      "        into device pinned memory before returning them if pin_memory is set to true.\n",
      "\n",
      "\n",
      ".. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
      "             cannot be an unpicklable object, e.g., a lambda function. See\n",
      "             :ref:`multiprocessing-best-practices` on more details related\n",
      "             to multiprocessing in PyTorch.\n",
      "\n",
      ".. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
      "             When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
      "             it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
      "             rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
      "             configurations. This represents the best guess PyTorch can make because PyTorch\n",
      "             trusts user :attr:`dataset` code in correctly handling multi-process\n",
      "             loading to avoid duplicate data.\n",
      "\n",
      "             However, if sharding results in multiple workers having incomplete last batches,\n",
      "             this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
      "             be broken into multiple ones and (2) more than one batch worth of samples can be\n",
      "             dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
      "             cases in general.\n",
      "\n",
      "             See `Dataset Types`_ for more details on these two types of datasets and how\n",
      "             :class:`~torch.utils.data.IterableDataset` interacts with\n",
      "             `Multi-process data loading`_.\n",
      "\n",
      ".. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
      "             :ref:`data-loading-randomness` notes for random seed related questions.\n",
      "\u001b[0;31mFile:\u001b[0m           ~/Data/miniconda3/envs/kaggle-env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     DataLoaderShard, DataLoaderDispatcher, SkipDataLoader\n"
     ]
    }
   ],
   "source": [
    "DataLoader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f694578c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35ac7bee214e4eb5b203f67d4fa1f620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/8.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a59e70e23d048028d8028f2ac059af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/14.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce9eec67246b4a3c9c08d2d3d8263daa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.65k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff85a8213894367a1cc34f551c2eff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/65.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['train', 'validation', 'test', 'other', 'invalidated']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dataset_split_names(\"mozilla-foundation/common_voice_13_0\", \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66681a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d5db098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid.\n",
      "Your token has been saved to /home/vamsik1211/.huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "huggingface_hub.login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3807f95e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
