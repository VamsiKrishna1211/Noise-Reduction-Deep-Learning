{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torchaudio as ta\n",
    "ta.set_audio_backend(\"sox_io\")\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd.profiler as profiler\n",
    "# from torch_lr_finder import LRFinder\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "import glob\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from python_files.Noise_Reduction_Datagen_fp16 import Signal_Synthesis_DataGen\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import gc\n",
    "\n",
    "# from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noise from saved file\n",
      "Loading nums from npy file\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "noise_dir = \"./dataset/UrbanSound8K-Resampled/audio/\"\n",
    "signal_dir = \"./dataset/cv-corpus-5.1-2020-06-22-Resampled/en/clips/\"\n",
    "signal_nums_save = \"./dataset_loader_files/signal_paths_nums_save.npy\"\n",
    "num_noise_samples=100\n",
    "num_signal_samples = 100\n",
    "noise_save_path = \"./dataset_loader_files/noise_paths_resampled_save.npy\"\n",
    "n_fft=1024\n",
    "win_length=n_fft\n",
    "hop_len=n_fft//4\n",
    "create_specgram = False\n",
    "perform_stft = False\n",
    "default_sr = 16000\n",
    "sec = 2\n",
    "augment=True\n",
    "device_datagen = \"cpu\"\n",
    "\n",
    "signal_synthesis_dataset = Signal_Synthesis_DataGen(noise_dir, signal_dir, \\\n",
    "                signal_nums_save=signal_nums_save, num_noise_samples=num_noise_samples, \\\n",
    "                num_signal_samples=num_signal_samples, noise_path_save=noise_save_path, \\\n",
    "                 n_fft=n_fft, win_length=win_length, hop_len=hop_len, create_specgram=create_specgram, \\\n",
    "                 perform_stft=perform_stft, normalize=True, default_sr=default_sr, sec=sec, epsilon=1e-5, augment=False, device=device_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "shuffle = True\n",
    "num_workers = 8\n",
    "pin_memory = False\n",
    "# data_loader = DataLoader(signal_synthesis_dataset, batch_size=BATCH_SIZE, shuffle=shuffle, num_workers=num_workers)\n",
    "data_loader = DataLoader(signal_synthesis_dataset, batch_size=BATCH_SIZE, shuffle=shuffle, num_workers=num_workers, pin_memory=pin_memory)\n",
    "# data_loader.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # data_loader_iter = iter(data_loader)\n",
    "# for index, i in enumerate(data_loader):\n",
    "# #     i = next(data_loader)\n",
    "#     if index < 32-1:\n",
    "#         pass\n",
    "#     else:\n",
    "#         break\n",
    "#     print(i[1].shape,i[0].min(), i[0].max(), i[0].dtype, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "stft_sig = torch.stft(i[0], n_fft=n_fft, hop_length=hop_len, win_length=win_length)\n",
    "istft_sig = torch.istft(stft_sig, n_fft=n_fft, hop_length=hop_len, win_length=win_length)\n",
    "i[1].max()\n",
    "\n",
    "nan_sig = signal_synthesis_dataset.__getitem__(119)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9998), tensor(1.0000e-05))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_sig[0].max(), nan_sig[1].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(560.1311)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stft_sig.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 513, 126, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stft_sig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32000])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "istft_sig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def normalize(tensor):\n",
    "    tensor_minusmean = tensor - tensor.min()\n",
    "    return tensor_minusmean/tensor_minusmean.abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# aud = i[0][0]\n",
    "\n",
    "# aud.dtype\n",
    "\n",
    "# aud.max(), aud.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# x = aud.t().to(\"cpu\").numpy()\n",
    "# ipd.Audio(x, rate=default_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# sig1 = i[0].unsqueeze(dim=1)\n",
    "# sig2 = i[0].unsqueeze(dim=1)\n",
    "# stacked_sig = torch.cat((sig1, sig2), dim=1)\n",
    "\n",
    "# sig2 = i[0].unsqueeze(dim=1)\n",
    "# sig2.shape\n",
    "\n",
    "# torch.sum(stacked_sig, dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.floor(((default_sr*sec) - (win_length - 1) - 1)/ hop_len + 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "513"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_fft // 2 + 1\n",
    "\n",
    "n_fft // 2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# stft_sig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstantLayerNormalization(pl.LightningModule):\n",
    "    def __init__(self, in_shape, out_shape):\n",
    "        self.in_shape = in_shape\n",
    "        self.out_shape = out_shape\n",
    "        \n",
    "        self.epsilon = 1e-7\n",
    "        self.gamma = None\n",
    "        self.beta = None\n",
    "        \n",
    "        super(InstantLayerNormalization, self).__init__()\n",
    "        \n",
    "        self.gamma = torch.ones(out_shape)\n",
    "        self.gamma = nn.Parameter(self.gamma)\n",
    "        \n",
    "        self.beta = torch.zeros(out_shape)\n",
    "        self.beta = nn.Parameter(self.beta)\n",
    "        \n",
    "    def forward(self, inps):\n",
    "        mean = inps.mean(-1, keepdim=True)\n",
    "        variance = torch.mean(torch.square(inps - mean), dim=-1, keepdim=True)\n",
    "        std = torch.sqrt(variance + self.epsilon)\n",
    "        \n",
    "        outs = (inps - mean) / std\n",
    "        print(outs.shape, self.gamma.shape)\n",
    "        outs = outs * self.gamma\n",
    "        outs = outs + self.beta\n",
    "        \n",
    "        return outs\n",
    "    \n",
    "class Multiply():\n",
    "    def __init__(self):\n",
    "        super(Multiply, self).__init__()\n",
    "    \n",
    "    def forward(self, ten1, ten2):\n",
    "        mul_out = torch.mul(ten1, ten2)\n",
    "        return mul_out\n",
    "    \n",
    "class Negative_SNR_Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Negative_SNR_Loss, self).__init__()\n",
    "    \n",
    "    def forward(self, sig_pred, sig_true):\n",
    "        \n",
    "        sig_true_sq = torch.square(sig_true)\n",
    "        sig_pred_sq = torch.square(sig_true - sig_pred)\n",
    "\n",
    "        sig_true_mean = torch.mean(sig_true_sq)\n",
    "        sig_pred_mean = torch.mean(sig_pred_sq)\n",
    "\n",
    "        snr = sig_true_mean / sig_pred_mean + 1e-7\n",
    "        loss = -1*torch.log10(snr)\n",
    "\n",
    "        return loss\n",
    "\n",
    "class NoiseReducer_Model(pl.LightningModule):\n",
    "    def __init__(self, default_sr, n_fft, win_length, hop_len, sec, dropout=0.5, batch_first=True, stride=2, normalized=False, bidir=False):\n",
    "        \n",
    "        self.default_sr = default_sr\n",
    "        self.n_fft = n_fft\n",
    "        self.win_length = win_length\n",
    "        self.hop_len = hop_len\n",
    "        self.sec = sec\n",
    "        self.normalized = normalized\n",
    "        self.loss_fn = nn.MSELoss(reduction=\"mean\")\n",
    "        \n",
    "        self.conv_filters = 512\n",
    "        \n",
    "        # Universal LSTM Units\n",
    "        self.batch_first = True\n",
    "        self.dropout = 0.25\n",
    "        self.bidir = bidir\n",
    "        self.lstm_prelu_ins = int(np.floor(((default_sr*sec) - (win_length - 1) - 1)/ hop_len + 5))\n",
    "        \n",
    "        # LSTM 1 UNITS\n",
    "        self.rnn1_dims = n_fft // 2 + 1\n",
    "        self.hidden_size_1 = 256\n",
    "        self.num_layers = 2\n",
    "       \n",
    "        \n",
    "        # LSTM 2 UNITS\n",
    "        self.rnn2_dims = self.conv_filters\n",
    "        self.hidden_size_2 = self.hidden_size_1\n",
    "        \n",
    "        # Conv1d Layer Units\n",
    "        self.conv1_in = 1\n",
    "        self.conv1_out = self.conv_filters\n",
    "        \n",
    "        \n",
    "        \n",
    "        # InstanceNorm Layer Units\n",
    "        self.instance1_in = self.rnn1_dims\n",
    "        self.instance2_in = self.conv1_out\n",
    "        \n",
    "        # Dense1 Layer Units\n",
    "        self.dense1_in = self.hidden_size_1\n",
    "        self.dense1_out = self.rnn1_dims #int(np.floor(((default_sr*sec) - (win_length - 1) - 1)/ hop_len + 5))#3))\n",
    "        \n",
    "        # Dense2 Layer Units\n",
    "        self.dense2_in = self.hidden_size_2\n",
    "        self.dense2_out = self.conv1_out\n",
    "        \n",
    "        # Dense3 Layer Units\n",
    "        self.dense3_in = self.hidden_size_1\n",
    "        self.dense3_out = self.rnn1_dims\n",
    "        \n",
    "        # Conv2d Layer Units\n",
    "        self.conv2_in = self.dense2_out\n",
    "        self.conv2_out = self.conv_filters\n",
    "        \n",
    "\n",
    "        super(NoiseReducer, self).__init__()\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size=self.rnn1_dims, hidden_size=self.hidden_size_1, num_layers=self.num_layers, batch_first=self.batch_first, dropout=self.dropout, bidirectional=self.bidir)\n",
    "        self.lstm3 = nn.LSTM(input_size=self.rnn1_dims, hidden_size=self.hidden_size_1, num_layers=self.num_layers, batch_first=self.batch_first, dropout=self.dropout, bidirectional=self.bidir)\n",
    "#         self.lstm1_1 = nn.LSTMCell(input_size=self.rnn1_dims, hidden_size==self.hidden_size_1, )\n",
    "        \n",
    "        print(self.rnn2_dims)\n",
    "        self.lstm2 = nn.LSTM(input_size=self.rnn2_dims, hidden_size=self.hidden_size_2, num_layers=self.num_layers*2, batch_first=self.batch_first, dropout=self.dropout, bidirectional=self.bidir)\n",
    "        \n",
    "        \n",
    "        self.instancenorm1 = nn.InstanceNorm1d(self.rnn1_dims)\n",
    "        self.instancenorm2 = nn.InstanceNorm1d(self.rnn2_dims)\n",
    "        self.instancenorm3 = nn.InstanceNorm1d(self.rnn1_dims)\n",
    "        \n",
    "        self.dense1 = nn.Linear(self.dense1_in, self.dense1_out)\n",
    "        self.dense2 = nn.Linear(self.dense2_in, self.dense2_out)\n",
    "        self.dense3 = nn.Linear(self.dense3_in, self.dense3_out)\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(self.conv1_in, self.conv1_out, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(self.conv2_in, self.conv2_out, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.prelu_conv1 = nn.PReLU(self.conv1_out)\n",
    "        self.prelu_conv2 = nn.PReLU(self.conv2_out)\n",
    "        \n",
    "        self.prelu_lstm1 = nn.PReLU(self.lstm_prelu_ins)\n",
    "        self.prelu_lstm3 = nn.PReLU(self.lstm_prelu_ins)\n",
    "        self.prelu_lstm2 = nn.PReLU(self.hidden_size_2)\n",
    "        \n",
    "    @torch.jit.export\n",
    "    def stft_layer(self, sig):\n",
    "        \n",
    "        sig_stft = torch.stft(sig, n_fft=self.n_fft, hop_length=self.hop_len, win_length=self.win_length)\n",
    "        \n",
    "        sig_cplx = torch.view_as_complex(sig_stft)\n",
    "        mag = sig_cplx.abs().permute(0, 2, 1)\n",
    "        angle = sig_cplx.angle().permute(0, 2, 1)\n",
    "\n",
    "#         mag = sig_stft[:,:,:,0].permute(0, 2, 1)\n",
    "#         angle = sig_stft[:,:,:,1].permute(0, 2, 1)\n",
    "        \n",
    "        return [mag, angle]\n",
    "    \n",
    "    @torch.jit.export\n",
    "    def istft_layer(self, mag, angle):\n",
    "        mag = mag.permute(0, 2, 1)\n",
    "        angle = angle.permute(0, 2, 1)\n",
    "        mag = torch.unsqueeze(mag, dim=-1)\n",
    "        angle = torch.unsqueeze(angle, dim=-1)\n",
    "        pre_stft = torch.cat((mag, angle), dim=-1)\n",
    "        stft_sig = torch.istft(pre_stft, n_fft=self.n_fft, win_length=self.win_length, hop_length=self.hop_len)\n",
    "        \n",
    "        return stft_sig\n",
    "    \n",
    "    @torch.cuda.amp.autocast()\n",
    "    def forward(self, inp_tensor):\n",
    "        \n",
    "        mag, angle = self.stft_layer(inp_tensor)\n",
    "        mag_norm = self.instancenorm1(mag)\n",
    "        angle_norm = self.instancenorm3(angle)\n",
    "        \n",
    "        x_mag, hidden_states_mag = self.lstm1(mag_norm)\n",
    "        x_angle, hidden_states_angle = self.lstm3(angle_norm)\n",
    "\n",
    "        mask_mag = F.relu(self.dense1(x_mag))\n",
    "        estimated_mag = torch.mul(mag, mask_mag)\n",
    "        \n",
    "        mask_angle = F.relu(self.dense3(x_angle))\n",
    "        estimated_angle = torch.mul(angle, mask_angle)\n",
    "        \n",
    "        signal = self.istft_layer(estimated_mag, estimated_angle)\n",
    "        signal = signal.unsqueeze(dim=1)\n",
    "\n",
    "        feature_rep = self.conv1(signal)\n",
    "        feature_rep = self.prelu_conv2(feature_rep)\n",
    "        \n",
    "        feature_norm = self.instancenorm2(feature_rep)\n",
    "        feature_norm = feature_norm.permute(0, 2, 1)\n",
    "        x, hidden_states = self.lstm2(feature_norm)\n",
    "        mask = self.dense2(x)\n",
    "        feature_mask = F.relu(mask)\n",
    "        feature_mask = feature_mask.permute(0, 2, 1)\n",
    "\n",
    "        estimate_feat = torch.mul(feature_rep, feature_mask)\n",
    "        \n",
    "        estimate_frames = (self.conv2(estimate_feat))\n",
    "        estimate_frames = self.prelu_conv2(estimate_frames)\n",
    "        estimate_sig = torch.sum(estimate_frames, dim=1)\n",
    "        \n",
    "        return estimate_sig\n",
    "    \n",
    "    def training_step(self, batch, batch_index):\n",
    "        data, target = batch\n",
    "        outputs = self.forward(data)\n",
    "        loss = self.calc_loss(outputs, targets)\n",
    "        return loss\n",
    "            \n",
    "        \n",
    "    def calc_loss(self, outputs, targets):\n",
    "        loss = self.loss_fn(outputs, targets)\n",
    "        return loss\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Primary model\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "use_scripted_model = False\n",
    "w_decay = 1e-4\n",
    "\n",
    "if not use_scripted_model:\n",
    "    print(\"Using Primary model\")\n",
    "    model = NoiseReducer(default_sr=default_sr, n_fft=n_fft, win_length=win_length, hop_len=hop_len, sec=sec).to(device)\n",
    "    model.to(device)\n",
    "else:\n",
    "    print(\"Using Scripted Model\")\n",
    "    model = scripted_model\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0)\n",
    "criterion = nn.MSELoss(reduction=\"mean\")#Negative_SNR_Loss()\n",
    "n_epochs=100\n",
    "\n",
    "# model = torch.cuda.amp.initialize(model, optimizer, opt_level=\"01\")\n",
    "\n",
    "model.train()\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake_inputs = torch.randn(BATCH_SIZE, int(default_sr*sec)).type(torch.float32).to(device)\n",
    "# outs = model(fake_inputs)\n",
    "# outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(\"./Model_saves/Pytorch_model_2_save_2_LSTM_256_filters.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, model, optimizer, criterion, data_loader, n_epochs=100, mixed_precision=True, save_path=None, device=\"cuda\"):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.data_loader = data_loader\n",
    "        self.n_epochs = n_epochs\n",
    "        self.mixed_precision = mixed_precision\n",
    "        self.save_path = save_path\n",
    "        self.device = device\n",
    "        if mixed_precision:\n",
    "            self.scaler = torch.cuda.amp.GradScaler()\n",
    "        \n",
    "        train_loss = np.zeros((epochs, len(data_loader)))\n",
    "        self.data_loop = tqdm(enumerate(self.data_loader), leave=True, total=len(self.data_loader))\n",
    "        \n",
    "        \n",
    "    def train_step(self, ):\n",
    "        outs = self.model(self.data)\n",
    "        \n",
    "    def data_step(self, epoch):\n",
    "        self.data_loop.set_description(f\"Epoch: [ {epoch}/{n_epochs} ]\\t\")\n",
    "        for index, (self.data, self.target) in self.data_loader:\n",
    "            self.data.to(self.device)\n",
    "            self.target.to(self.device)\n",
    "            self.optimizer.zero_grad(set_to_none=True)\n",
    "            if self.mixed_precision:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    self.output = self.model(self.data)\n",
    "                    self.loss = self.criterion(self.output, self.target)\n",
    "                self.scaler.scale(self.loss).backward()\n",
    "                self.scaler.step(self.optimizer)\n",
    "                self.scaler.update()\n",
    "            else:\n",
    "                self.output = self.model(self.data)\n",
    "                self.loss = self.criterion(self.output, self.target)\n",
    "                self.loss.backward()\n",
    "                self.optimizer.step()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba5688fae9394307ab31216d22ac8856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-1a4eba79dc75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch-source/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch-source/lib/python3.7/site-packages/torch/cuda/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-7ee61ac7e182>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp_tensor)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mfeature_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstancenorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_rep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mfeature_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mfeature_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch-source/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch-source/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 582\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    583\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    \n",
    "    loop = tqdm(enumerate(data_loader), leave=True, total=len(data_loader))\n",
    "    train_loss = np.zeros((len(data_loader)))\n",
    "    loop.set_description(f\"Epoch: [ {epoch}/{n_epochs} ]\\t\")\n",
    "\n",
    "    \n",
    "    for index, (data, target) in loop:\n",
    "        \n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        for group in optimizer.param_groups:\n",
    "            for param in group[\"params\"]:\n",
    "                param.data = param.data.add(-w_decay * group[\"lr\"], param.data)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "#         output = model(data)\n",
    "#         loss = criterion(output, target)\n",
    "        \n",
    "#         loss.backward()\n",
    "#         for group in optimizer.param_groups:\n",
    "#             for param in group[\"params\"]:\n",
    "#                 param.data = param.data.add(-w_decay * group[\"lr\"], param.data)\n",
    "#         optimizer.step()\n",
    "\n",
    "        train_loss[index] = loss.item()\n",
    "        if np.isnan(loss.item()) or np.isnan(np.sum(train_loss)/index+1e-5):\n",
    "            print(f\"Data shape = {data.shape}\\nTarget Shape = {target.shape}, \\nindex = {index}\")\n",
    "        disp_loss = np.sum(train_loss)/index+1e-5\n",
    "        loop.set_postfix(loss = disp_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.closure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./Model_saves/Pytorch_model_2_save_LSTM_512_filters.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_add_sig, main_sig = signal_synthesis_dataset.__getitem__(1000)\n",
    "noise_add_sig = torch.unsqueeze(noise_add_sig, dim=0).to(device)\n",
    "main_sig = torch.unsqueeze(main_sig, dim=0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    outs = model(noise_add_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_loss = torch.nn.CosineSimilarity()(main_sig, outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sim_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = outs[0].t().to(\"cpu\").numpy()\n",
    "ipd.Audio(x, rate=default_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = noise_add_sig[0].t().to(\"cpu\").numpy()\n",
    "ipd.Audio(x, rate=default_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = main_sig[0].t().to(\"cpu\").numpy()\n",
    "ipd.Audio(x, rate=default_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_add_sig.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
