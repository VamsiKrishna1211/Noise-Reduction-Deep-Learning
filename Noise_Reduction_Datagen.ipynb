{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio as ta\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "\n",
    "from random import shuffle\n",
    "import gc\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Signal_Synthesis_DataGen(Dataset):\n",
    "    def __init__(self, noise_dir, signal_dir, num_samples=200, noise_path_save=None,\\\n",
    "                 n_fft=400, win_length=400, hop_len=200, f_min=0, f_max=8000, \\\n",
    "                 perform_stft=True, normalize=True, default_sr=16000, sec=6, augment=False):\n",
    "\n",
    "        self.noise_dir = noise_dir\n",
    "        self.signal_dir = signal_dir\n",
    "        self.noise_path_save = noise_path_save\n",
    "        self.n_fft = n_fft\n",
    "        self.win_length = win_length\n",
    "        self.hop_len = hop_len\n",
    "        self.f_min = f_min\n",
    "        self.f_max = f_max\n",
    "        self.perform_stft = perform_stft\n",
    "        self.normalize = normalize\n",
    "        self.default_sr = default_sr\n",
    "        self.sec = sec\n",
    "        self.augment = augment\n",
    "\n",
    "\n",
    "\n",
    "        self.noise_nums = self.get_noise_paths(noise_dir)\n",
    "        self.noise_nums = self.noise_nums[:num_samples]\n",
    "        self.noise_suffix = \".wav\"\n",
    "\n",
    "        self.signal_nums = self.get_signal_paths(signal_dir)\n",
    "        self.signal_prefix = \"common_voice_en_\"\n",
    "        self.signal_suffix = \".mp3\"\n",
    "\n",
    "\n",
    "    def get_noise_paths(self, noise_dir):\n",
    "        file_nums = []\n",
    "        for file in tqdm(os.listdir(noise_dir)):\n",
    "            num = int(file.split(\".\")[0])\n",
    "            file_nums.append(num)\n",
    "        file_nums = np.asarray(file_nums)\n",
    "        return file_nums\n",
    "\n",
    "    def get_signal_paths(self, clips_path):\n",
    "\n",
    "        file_nums = []\n",
    "        for file in tqdm(os.listdir(clips_path)):\n",
    "            num = file.split(\"_\")[3]\n",
    "            num = int(num.split(\".\")[0])\n",
    "            file_nums.append(num)\n",
    "        file_nums = np.asarray(file_nums)\n",
    "        return file_nums\n",
    "\n",
    "\n",
    "\n",
    "    def get_noise_from_sound(self, signal, noise, SNR):\n",
    "\n",
    "        RMS_s = np.sqrt(np.mean(signal**2))\n",
    "\n",
    "        RMS_n = np.sqrt(RMS_s**2/pow(10., SNR/10))\n",
    "\n",
    "        RMS_n_current = np.sqrt(np.mean(noise**2))\n",
    "        noise = noise*(RMS_n/RMS_n_current)\n",
    "\n",
    "        return noise\n",
    "\n",
    "\n",
    "\n",
    "    def get_mixed_signal(self, signal: torch.Tensor, noise: torch.Tensor, default_sr, sec, SNR):\n",
    "\n",
    "        snip_audio = np.random.randint(0, 2)\n",
    "        # if snip_audio:\n",
    "        #     signal = ta.transforms.Vad(sample_rate=default_sr)(signal)\n",
    "\n",
    "        sig_length = int(default_sr * sec)\n",
    "\n",
    "        if len(signal) > sig_length:\n",
    "            signal = signal[: sig_length]\n",
    "        elif len(signal) <= sig_length:\n",
    "            zero_signal = np.zeros((signal.shape))\n",
    "            while len(signal) < sig_length:\n",
    "                signal = np.concatenate((signal, zero_signal))\n",
    "                zero_signal = np.zeros(signal.shape)\n",
    "            signal = signal[ : sig_length]\n",
    "\n",
    "\n",
    "        noise_len = len(noise)\n",
    "        signal_len = len(signal)\n",
    "\n",
    "        if len(noise) > len(signal):\n",
    "            noise = noise[0 : len(signal)]\n",
    "        elif len(noise) <= len(signal):\n",
    "\n",
    "            #noise = torch.cat((noise, torch.zeros((len(signal) - len(noise)))))\n",
    "            for i in range(int(len(signal)/len(noise))+1):\n",
    "                noise = np.concatenate((noise, noise))\n",
    "\n",
    "            noise = noise[:len(signal)]\n",
    "\n",
    "        noise = self.get_noise_from_sound(signal, noise, SNR)\n",
    "\n",
    "        signal_noise = signal+noise\n",
    "        return signal_noise, signal\n",
    "\n",
    "    def construct_signal_path(self, signal_id):\n",
    "        file_num = str(self.signal_nums[signal_id])\n",
    "        file_name = self.signal_prefix + str(file_num) + self.signal_suffix\n",
    "        path = os.path.join(self.signal_dir, file_name)\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "        else:\n",
    "            raise FileExistsError(f\"{path}\")\n",
    "            \n",
    "    def construct_noise_path(self, noise_id):\n",
    "        file_num = str(self.noise_nums[noise_id])\n",
    "        file_name = file_num + self.noise_suffix\n",
    "        path = os.path.join(self.noise_dir, file_name)\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "        else:\n",
    "            raise FileExistsError(f\"{path}\")\n",
    "\n",
    "\n",
    "\n",
    "    def get_ids(self, signal_paths, noise_paths, idx):\n",
    "\n",
    "        signal_id = idx//len(noise_paths)\n",
    "        noise_id = idx - signal_id*len(noise_paths)\n",
    "#         print(signal_id, noise_id)\n",
    "\n",
    "        signal_path, noise_path = self.construct_signal_path(signal_id), self.construct_noise_path(noise_id)\n",
    "\n",
    "        signal_noise_add, signal = self.develop_data(signal_path, noise_path)\n",
    "\n",
    "        return signal_noise_add, signal\n",
    "\n",
    "    def develop_data(self, signal_path, noise_path):\n",
    "\n",
    "        SNR = np.random.randint(0, np.random.randint(0, 50)+1)\n",
    "#         print(SNR)\n",
    "\n",
    "        noise, nsr = librosa.load(noise_path, sr=self.default_sr)\n",
    "        signal, ssr = librosa.load(signal_path, sr=self.default_sr)\n",
    "        # noise, nsr = ta.load(noise_path)\n",
    "        # noise = ta.transforms.Resample(orig_freq=nsr, new_freq=self.default_sr)(noise)\n",
    "        # signal, ssr = ta.load(signal_path)\n",
    "        # signal = ta.transforms.Resample(orig_freq=ssr, new_freq=self.default_sr)(signal)\n",
    "        # noise = torch.from_numpy(noise)\n",
    "        # signal = torch.from_numpy(signal)\n",
    "\n",
    "        signal_noise_add, signal = self.get_mixed_signal(signal, noise, self.default_sr, self.sec, SNR)\n",
    "        if self.perform_stft:\n",
    "            signal_noise_add = librosa.stft(signal_noise_add, n_fft=self.n_fft, hop_length=self.hop_len, win_length=self.win_length)\n",
    "            signal = librosa.stft(signal, n_fft=self.n_fft, hop_length=self.hop_len, win_length=self.win_length)\n",
    "            # (signal_noise_add, signal) = torch.stft(combined_signal, n_fft=self.n_fft, hop_length=self.hop_len, win_length=self.win_length, normalized=self.normalize)\n",
    "\n",
    "        return signal_noise_add, signal\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.signal_nums)*len(self.noise_nums)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        signal_noise_add, signal = self.get_ids(self.signal_nums, self.noise_nums, idx)\n",
    "        gc.collect()\n",
    "\n",
    "#         signal_noise_add, signal = signal_noise_add/signal_noise_add.max(), signal/signal.max()\n",
    "        # print(\"returning the values from getitem dataset\")\n",
    "        return signal_noise_add, signal\n",
    "#         return signal_noise_add, signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0eb03bd4f6341d982ec8e67ce4b33ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'fold5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7a75b0ab9c84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0msignal_synthesis_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSignal_Synthesis_DataGen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignal_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignal_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignal_save_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_save_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0msignal_mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal_synthesis_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4532\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal_mix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-652466b82aab>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, noise_dir, signal_dir, num_samples, noise_path_save, n_fft, win_length, hop_len, f_min, f_max, perform_stft, normalize, default_sr, sec, augment)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise_nums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_noise_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise_nums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise_nums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise_suffix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\".wav\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-652466b82aab>\u001b[0m in \u001b[0;36mget_noise_paths\u001b[0;34m(self, noise_dir)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mfile_nums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mfile_nums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mfile_nums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_nums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'fold5'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    noise_dir = \"./dataset/UrbanSound8K/audio/\"\n",
    "    noise_metadata = \"./dataset/UrbanSound8K/metadata/UrbanSound8K.csv\"\n",
    "    signal_dir = \"./dataset/cv-corpus-5.1-2020-06-22/en/clips/\"\n",
    "    signal_metadata = \"./dataset/cv-corpus-5.1-2020-06-22/en/train.tsv\"\n",
    "    num_samples = 1000\n",
    "    use_df = True\n",
    "    df_path = \"./dataset/cv-corpus-5.1-2020-06-22/en/train.tsv\"\n",
    "    signal_save_path = \"./signal_paths_save.npy\"\n",
    "    noise_save_path = \"./noise_paths_save.npy\"\n",
    "    default_sr = 16000\n",
    "    sec = 6\n",
    "    augment=False\n",
    "\n",
    "\n",
    "    signal_synthesis_dataset = Signal_Synthesis_DataGen(noise_dir, noise_metadata, signal_dir, signal_metadata, num_samples, use_df, df_path, signal_save_path, noise_save_path, default_sr, sec, augment)\n",
    "    signal_mix, signal = signal_synthesis_dataset.__getitem__(4532)\n",
    "    print(signal_mix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dir = \"./dataset/UrbanSound8K/all_files/\"\n",
    "signal_dir = \"./dataset/cv-corpus-5.1-2020-06-22/en/clips/\"\n",
    "num_samples=200, \n",
    "noise_path_save = \"./noise_paths_save.npy\"\n",
    "default_sr = 16000\n",
    "sec = 6\n",
    "augment=False\n",
    "\n",
    "signal_synthesis_dataset = Signal_Synthesis_DataGen(noise_dir, signal_dir, num_samples=200, noise_path_save=noise_path_save,\\\n",
    "                 n_fft=400, win_length=400, hop_len=200, f_min=0, f_max=8000, \\\n",
    "                 perform_stft=True, normalize=True, default_sr=16000, sec=6, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_mix, signal = signal_synthesis_dataset.__getitem__(4532)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(signal_mix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(signal_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(signal_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
