{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Signal_Synthesis_Datagen_tf(Sequence):\n",
    "    def __init__(self, noise_dir, signal_dir, signal_nums_save=None, num_noise_samples=None, num_signal_samples=None, noise_path_save=None,\\\n",
    "                 n_fft=400, win_length=400, hop_len=200, create_specgram=False, \\\n",
    "                 perform_stft=True, normalize=True, default_sr=16000, sec=6, batch_size=32, shuffle=True, augment=False):\n",
    "        \n",
    "        self.noise_dir = noise_dir\n",
    "        self.signal_dir = signal_dir\n",
    "        self.signal_nums_save = signal_nums_save\n",
    "        self.num_noise_samples = num_noise_samples\n",
    "        self.num_signal_samples = num_signal_samples\n",
    "        self.noise_path_save = noise_path_save\n",
    "        self.n_fft = n_fft\n",
    "        self.win_length = win_length\n",
    "        self.hop_len = hop_len\n",
    "        self.create_specgram = create_specgram\n",
    "        self.perform_stft = perform_stft\n",
    "        self.normalize = normalize\n",
    "        self.default_sr = default_sr\n",
    "        self.sec = sec\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        \n",
    "        \n",
    "        if self.create_specgram == True and self.perform_stft == True:\n",
    "            raise Exception(\"Use only one option out of 'create_specgram' and 'perform_stft'\")\n",
    "            \n",
    "        if os.path.exists(self.noise_path_save):\n",
    "            print(\"Loading noise from saved file\")\n",
    "            noise_paths = np.load(self.noise_path_save)\n",
    "        else:\n",
    "            noise_paths = []\n",
    "            for root, dirs, files in os.walk(noise_dir):\n",
    "                for name in files:\n",
    "                    if name.endswith(\".wav\"):\n",
    "                        noise_paths.append(os.path.join(root, name))\n",
    "            noise_paths = np.asarray(noise_paths)\n",
    "            \n",
    "        if self.num_noise_samples is not None:\n",
    "            self.noise_paths = noise_paths[:self.num_noise_samples]\n",
    "        else:\n",
    "            self.noise_paths = noise_paths\n",
    "            \n",
    "        if os.path.exists(signal_nums_save):\n",
    "            print(\"Loading nums from npy file\")\n",
    "            self.signal_nums = np.load(signal_nums_save)\n",
    "        else:\n",
    "            self.signal_nums = self.get_signal_paths(signal_dir)\n",
    "            \n",
    "            \n",
    "        if self.num_signal_samples is not None:\n",
    "            self.signal_nums = self.signal_nums[:self.num_signal_samples]\n",
    "        print(len(self.signal_nums))\n",
    "        self.prefix = \"common_voice_en_\"\n",
    "        self.suffix = \".mp3\"\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "        \n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        self.ids = np.arange(len(self.signal_nums)*len(self.noise_paths))\n",
    "        \n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.ids)\n",
    "            \n",
    "        \n",
    "        \n",
    "    def get_signal_paths(self, clips_path):\n",
    "\n",
    "        file_nums = []\n",
    "        for file in tqdm(os.listdir(clips_path)):\n",
    "            num = file.split(\"_\")[3]\n",
    "            num = int(num.split(\".\")[0])\n",
    "            file_nums.append(num)\n",
    "        file_nums = np.asarray(file_nums)\n",
    "        return file_nums\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_noise_from_sound(self, signal, noise, SNR):\n",
    "\n",
    "        RMS_s = np.sqrt(np.mean(signal**2))\n",
    "\n",
    "        RMS_n = np.sqrt(RMS_s**2/pow(10., SNR/10))\n",
    "\n",
    "        RMS_n_current = np.sqrt(torch.mean(np.square(noise)))\n",
    "        noise = noise*(RMS_n/RMS_n_current)\n",
    "\n",
    "        return noise\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_mixed_signal(self, signal, noise, default_sr, sec, SNR):\n",
    "\n",
    "        snip_audio = np.random.randint(0, 2)\n",
    "        # if snip_audio:\n",
    "        #     signal = ta.transforms.Vad(sample_rate=default_sr)(signal)\n",
    "\n",
    "        sig_length = int(default_sr * sec)\n",
    "\n",
    "        if len(signal) > sig_length:\n",
    "            signal = signal[: sig_length]\n",
    "        elif len(signal) <= sig_length:\n",
    "            zero_signal = np.zeros((signal.shape))\n",
    "            while len(signal) < sig_length:\n",
    "                signal = np.concatenate((signal, zero_signal))\n",
    "                zero_signal = np.zeros(signal.shape)\n",
    "            signal = signal[ : sig_length]\n",
    "            \n",
    "        noise_len = len(noise)\n",
    "        signal_len = len(signal)\n",
    "\n",
    "        if len(noise) > len(signal):\n",
    "            noise = noise[0 : len(signal)]\n",
    "        elif len(noise) <= len(signal):\n",
    "\n",
    "            #noise = torch.cat((noise, torch.zeros((len(signal) - len(noise)))))\n",
    "            for i in range(int(len(signal)/len(noise))+1):\n",
    "                noise = np.concatenate((noise, noise))\n",
    "\n",
    "            noise = noise[:len(signal)]\n",
    "\n",
    "        noise = self.get_noise_from_sound(signal, noise, SNR)\n",
    "\n",
    "        signal_noise = signal+noise\n",
    "        return signal_noise, signal\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def construct_signal_path(self, signal_id):\n",
    "\n",
    "        file_num = self.signal_nums[signal_id]\n",
    "        if torch.is_tensor(file_num):\n",
    "            # print(\"Enter_tensor\")\n",
    "            file_num = file_num.item()\n",
    "        file_name = self.prefix + str(file_num) + self.suffix\n",
    "        path = os.path.join(self.signal_dir, file_name)\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "        else:\n",
    "            raise FileExistsError(f\"{path}\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    def get_ids(self, idx):\n",
    "\n",
    "        signal_id = idx//len(self.noise_paths)\n",
    "        noise_id = idx - signal_id*len(self.noise_paths)\n",
    "#         print(signal_id, noise_id)\n",
    "\n",
    "        signal_path, noise_path = self.construct_signal_path(signal_id), self.noise_paths[noise_id]\n",
    "\n",
    "        signal_noise_add, signal = self.develop_data(signal_path, noise_path)\n",
    "\n",
    "        return signal_noise_add, signal\n",
    "    \n",
    "    def develop_data(self, signal_path, noise_path):\n",
    "\n",
    "        SNR = np.random.randint(0, np.random.randint(0, 50)+1)\n",
    "#         print(SNR)\n",
    "\n",
    "        noise, nsr = librosa.load(noise_path, sr=self.default_sr)\n",
    "        signal, ssr = librosa.load(signal_path, sr=self.default_sr)\n",
    "        \n",
    "        signal_noise_add, signal = self.get_mixed_signal(signal, noise, self.default_sr, self.sec, SNR)\n",
    "        \n",
    "        if self.perform_stft:\n",
    "            signal_noise_add = librosa.stft(signal_noise_add, n_fft=self.n_fft, hop_length=self.hop_len, win_length=self.win_length)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.signal_nums)*len(self.noise_paths)/self.batch_size\n",
    "    \n",
    "    def get_item(self, idx):\n",
    "        \n",
    "        signal_noise_add, signal = self.get_ids(idx)\n",
    "        \n",
    "        return signal_noise_add, signal\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.ids[index*self.batch_size : (index+1)*self.batch_size]\n",
    "        signal_noises = []\n",
    "        signals = []\n",
    "        for idx in indexes:\n",
    "            signal_noise, signal = self.get_item(idx)\n",
    "            signal_noises.append(signal_noise)\n",
    "            signals.append(signal)\n",
    "            \n",
    "        return np.asarray(signal_noises), np.asarray(signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Signal_Synthesis_Datagen_tf' object has no attribute 'signal_nums'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-334d8f127c70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mnum_signal_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_signal_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_path_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoise_save_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                  \u001b[0mn_fft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwin_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhop_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_specgram\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_specgram\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                  perform_stft=perform_stft, normalize=True, default_sr=default_sr, sec=sec, augment=False)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-639321dbccff>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, noise_dir, signal_dir, signal_nums_save, num_noise_samples, num_signal_samples, noise_path_save, n_fft, win_length, hop_len, create_specgram, perform_stft, normalize, default_sr, sec, batch_size, shuffle, augment)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_specgram\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform_stft\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-639321dbccff>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal_nums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Signal_Synthesis_Datagen_tf' object has no attribute 'signal_nums'"
     ]
    }
   ],
   "source": [
    "noise_dir = \"./dataset/UrbanSound8K-Resampled/audio/\"\n",
    "signal_dir = \"./dataset/cv-corpus-5.1-2020-06-22-Resampled/en/clips/\"\n",
    "signal_nums_save = \"./dataset_loader_files/signal_paths_nums_save.npy\"\n",
    "num_noise_samples=100\n",
    "num_signal_samples = 1000\n",
    "noise_save_path = \"./dataset_loader_files/noise_paths_resampled_save.npy\"\n",
    "n_fft=400\n",
    "win_length=n_fft\n",
    "hop_len=n_fft//4\n",
    "create_specgram = False\n",
    "perform_stft = False\n",
    "default_sr = 16000\n",
    "sec = 6\n",
    "augment=True\n",
    "\n",
    "signal_synthesis_dataset = Signal_Synthesis_Datagen_tf(noise_dir, signal_dir, \\\n",
    "                signal_nums_save=signal_nums_save, num_noise_samples=num_noise_samples, \\\n",
    "                num_signal_samples=num_signal_samples, noise_path_save=noise_save_path, \\\n",
    "                 n_fft=n_fft, win_length=win_length, hop_len=hop_len, create_specgram=create_specgram, \\\n",
    "                 perform_stft=perform_stft, normalize=True, default_sr=default_sr, sec=sec, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(\"./dataset_loader_files/signal_paths_nums_save.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
