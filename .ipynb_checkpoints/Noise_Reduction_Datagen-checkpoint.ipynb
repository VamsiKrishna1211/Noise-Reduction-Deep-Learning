{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio as ta\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "\n",
    "import librosa\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Signal_Synthesis_DataGen(Dataset):\n",
    "    def __init__(self, noise_dir, noise_metadata, signal_dir, signal_metadata, num_samples=200, signal_path_save=None, noise_path_save=None, \\\n",
    "                 n_fft=400, win_length=400, hop_len=200, f_min=0, f_max=8000, \\\n",
    "                 perform_stft=True, normalize=True, default_sr=16000, sec=6, augment=False):\n",
    "        \n",
    "        self.noise_dir = noise_dir\n",
    "        self.noise_metadata = noise_metadata\n",
    "        self.signal_dir = signal_dir\n",
    "        self.signal_metadata = signal_metadata\n",
    "        self.signal_path_save = signal_path_save\n",
    "        self.noise_path_save = noise_path_save\n",
    "        self.n_fft = n_fft\n",
    "        self.win_length = win_length\n",
    "        self.hop_len = hop_len\n",
    "        self.f_min = f_min\n",
    "        self.f_max = f_max\n",
    "        self.perform_stft = perform_stft\n",
    "        self.normalize = normalize\n",
    "        self.default_sr = default_sr\n",
    "        self.sec = sec\n",
    "        self.augment = augment\n",
    "        \n",
    "        if os.path.exists(self.noise_path_save):\n",
    "            noise_paths = np.load(self.noise_path_save)\n",
    "        else:\n",
    "            noise_paths = []\n",
    "            for root, dirs, files in os.walk(noise_dir):\n",
    "                for name in files:\n",
    "                    if name.endswith(\".wav\"):\n",
    "                        noise_paths.append(os.path.join(root, name))\n",
    "            noise_paths = np.asarray(noise_paths)\n",
    "#         shuffle(noise_paths)\n",
    "        self.noise_paths = noise_paths[:num_samples]\n",
    "        \n",
    "        if os.path.exists(self.signal_path_save):\n",
    "            print(\"Loading from npy file\")\n",
    "            self.signal_paths = np.load(self.signal_path_save)\n",
    "            \n",
    "        else:\n",
    "            print(\"Loading from the directories\")\n",
    "            self.signal_paths = self.get_sinal_paths(self.signal_dir)\n",
    "            \n",
    "        #self.data_list = self.make_data_list(self.signal_paths, self.noise_paths)\n",
    "        \n",
    "        \n",
    "            \n",
    "    def get_sinal_paths(self, signal_dir):\n",
    "\n",
    "        signal_paths = []\n",
    "        for file in tqdm(os.listdir(signal_dir)):\n",
    "            if file.endswith(\".mp3\"):\n",
    "                signal_paths.append(os.path.join(signal_dir, file))\n",
    "        return signal_paths\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_noise_from_sound(self, signal, noise, SNR):\n",
    "        \n",
    "        RMS_s = torch.sqrt(torch.mean(signal**2))\n",
    "\n",
    "        RMS_n = torch.sqrt(RMS_s**2/pow(10., SNR/10))\n",
    "\n",
    "        RMS_n_current = torch.sqrt(torch.mean(noise**2))\n",
    "        noise = noise*(RMS_n/RMS_n_current)\n",
    "\n",
    "        return noise\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_mixed_signal(self, signal: torch.Tensor, noise: torch.Tensor, default_sr, sec, SNR):\n",
    "        \n",
    "        snip_audio = np.random.randint(0, 2)\n",
    "        if snip_audio:\n",
    "            signal = ta.transforms.Vad(sample_rate=default_sr)(signal)\n",
    "        \n",
    "        sig_length = int(default_sr * sec)\n",
    "        \n",
    "        if len(signal) > sig_length:\n",
    "            signal = signal[: sig_length]\n",
    "        elif len(signal) <= sig_length:\n",
    "            zero_signal = torch.zeros((signal.size()))\n",
    "            while len(signal) < sig_length:\n",
    "                signal = torch.cat((signal, zero_signal))\n",
    "                zero_signal = torch.zeros(signal.size())\n",
    "            signal = signal[ : sig_length]\n",
    "        \n",
    "    \n",
    "        noise_len = len(noise)\n",
    "        signal_len = len(signal)\n",
    "\n",
    "        if len(noise) > len(signal):\n",
    "            noise = noise[0 : len(signal)]\n",
    "        elif len(noise) <= len(signal):\n",
    "\n",
    "            #noise = torch.cat((noise, torch.zeros((len(signal) - len(noise)))))\n",
    "            for i in range(int(len(signal)/len(noise))+1):\n",
    "                noise = torch.cat((noise, noise))\n",
    "\n",
    "            noise = noise[:len(signal)]\n",
    "\n",
    "        noise = self.get_noise_from_sound(signal, noise, SNR)\n",
    "\n",
    "        signal_noise = signal+noise\n",
    "        return signal_noise, signal\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_ids(self, signal_paths, noise_paths, idx):\n",
    "\n",
    "        signal_id = idx//len(noise_paths)\n",
    "        noise_id = idx - signal_id*len(noise_paths)\n",
    "#         print(signal_id, noise_id)\n",
    "        signal_path, noise_path = signal_paths[signal_id], noise_paths[noise_id]\n",
    "        \n",
    "        return signal_path, noise_path\n",
    "        \n",
    "    def develop_data(self, signal_path, noise_path):\n",
    "        \n",
    "        SNR = np.random.randint(0, np.random.randint(0, 50)+1)\n",
    "#         print(SNR)\n",
    "        \n",
    "        noise, nsr = librosa.load(noise_path, sr=self.default_sr)\n",
    "        signal, ssr = librosa.load(signal_path, sr=self.default_sr)\n",
    "        \n",
    "        noise = torch.from_numpy(noise)\n",
    "        signal = torch.from_numpy(signal)\n",
    "        \n",
    "        signal_noise_add, signal = self.get_mixed_signal(signal, noise, self.default_sr, self.sec, SNR)\n",
    "        if self.perform_stft:\n",
    "            signal_noise_add, signal = torch.unsqueeze(signal_noise_add, 0), torch.unsqueeze(signal, 0)\n",
    "            combined_signal = torch.cat([signal_noise_add, signal], 0)\n",
    "            (signal_noise_add, signal) = torch.stft(combined_signal, n_fft=self.n_fft, hop_length=self.hop_len, win_length=self.win_length, normalized=self.normalize)\n",
    "        \n",
    "        return torch.squeeze(signal_noise_add, 0), torch.squeeze(signal, 0)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "    \n",
    "        return len(self.signal_paths)*len(self.noise_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        signal_path, noise_path = self.get_ids(self.signal_paths, self.noise_paths, idx)\n",
    "        \n",
    "        signal_noise_add, signal = self.develop_data(signal_path, noise_path)\n",
    "#         signal_noise_add, signal = signal_noise_add/signal_noise_add.max(), signal/signal.max()\n",
    "        \n",
    "        return signal_noise_add, signal\n",
    "#         return signal_noise_add, signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from npy file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vamsik1211/Data/ML/lib/python3.7/site-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    noise_dir = \"./dataset/UrbanSound8K/audio/\"\n",
    "    noise_metadata = \"./dataset/UrbanSound8K/metadata/UrbanSound8K.csv\"\n",
    "    signal_dir = \"./dataset/cv-corpus-5.1-2020-06-22/en/clips/\"\n",
    "    signal_metadata = \"./dataset/cv-corpus-5.1-2020-06-22/en/train.tsv\"\n",
    "    num_samples = 1000\n",
    "    signal_save_path = \"./dataset_loader_files/signal_paths_save.npy\"\n",
    "    noise_save_path = \"./dataset_loader_files/noise_paths_save.npy\"\n",
    "    default_sr = 16000\n",
    "    sec = 4\n",
    "    augment=False\n",
    "\n",
    "    \n",
    "    signal_synthesis_dataset = Signal_Synthesis_DataGen(noise_dir, noise_metadata, signal_dir, signal_metadata, num_samples, signal_save_path, noise_save_path, default_sr=default_sr, sec=sec, augment=augment)\n",
    "    signal_mix, signal = signal_synthesis_dataset.__getitem__(29348)\n",
    "\n",
    "# x = signal_mix.numpy()\n",
    "# ipd.Audio(x, rate=default_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
