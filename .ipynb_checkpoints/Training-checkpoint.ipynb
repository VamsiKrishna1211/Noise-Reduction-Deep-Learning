{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio as ta\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import pytorch_lightning as pl\n",
    "\n",
    "import os\n",
    "\n",
    "import librosa\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import glob\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from Noise_Reduction_Datagen_numpy_ver import Signal_Synthesis_DataGen\n",
    "from Noise_Data_Loader import Noise_Data_loader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import gc\n",
    "\n",
    "# from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise_dir = \"./dataset/UrbanSound8K/audio/\"\n",
    "# noise_metadata = \"./dataset/UrbanSound8K/metadata/UrbanSound8K.csv\"\n",
    "# signal_dir = \"./dataset/cv-corpus-5.1-2020-06-22/en/clips/\"\n",
    "# signal_metadata = \"./dataset/cv-corpus-5.1-2020-06-22/en/train.tsv\"\n",
    "# num_samples = 1000\n",
    "# use_df = True\n",
    "# df_path = \"./dataset/cv-corpus-5.1-2020-06-22/en/train.tsv\"\n",
    "# signal_save_path = \"./dataset_loader_files/signal_paths_save.npy\"\n",
    "# noise_save_path = \"./dataset_loader_files/noise_paths_save.npy\"\n",
    "# default_sr = 16000\n",
    "# sec = 6\n",
    "# augment=False\n",
    "\n",
    "# signal_synthesis_dataset = Signal_Synthesis_DataGen(\n",
    "#                                 noise_dir=noise_dir,\n",
    "#                                 noise_metadata=noise_metadata,\n",
    "#                                 signal_dir=signal_dir,\n",
    "#                                 signal_metadata=signal_metadata,\n",
    "#                                 num_samples=num_samples,\n",
    "#                                 use_df=use_df,\n",
    "#                                 df_path=df_path,\n",
    "#                                 signal_path_save=signal_save_path,\n",
    "#                                 noise_path_save=noise_save_path,\n",
    "#                                 default_sr=default_sr,\n",
    "#                                 sec=sec,\n",
    "#                                 augment=augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noise from saved file\n",
      "(8000,)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "slice indices must be integers or None or have an __index__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f9778dcfce39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mnum_signal_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_noise_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_path_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoise_save_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                  \u001b[0mn_fft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                  perform_stft=True, normalize=True, default_sr=16000, sec=6, augment=False)\n\u001b[0m",
      "\u001b[0;32m~/Data/git-repos/Noise-Reduction-Deep-Learning/Noise_Reduction_Datagen_numpy_ver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, noise_dir, signal_dir, signal_nums_save, num_noise_samples, num_signal_samples, noise_path_save, n_fft, win_length, hop_len, f_min, f_max, perform_stft, normalize, default_sr, sec, augment)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_noise_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_noise_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoise_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_noise_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal_nums_save\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading nums from npy file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"
     ]
    }
   ],
   "source": [
    "noise_dir = \"./dataset/UrbanSound8K/all_files/\"\n",
    "signal_dir = \"./dataset/cv-corpus-5.1-2020-06-22/en/clips/\"\n",
    "signal_nums_save = \"./dataset_loader_files/signal_paths_nums_save.npy\"\n",
    "num_noise_samples=8000\n",
    "noise_save_path = \"./dataset_loader_files/noise_paths_save.npy\"\n",
    "default_sr = 16000\n",
    "sec = 6\n",
    "augment=True\n",
    "\n",
    "signal_synthesis_dataset = Signal_Synthesis_DataGen(noise_dir, signal_dir, \\\n",
    "                signal_nums_save=signal_nums_save, num_noise_samples=num_noise_samples, \\\n",
    "                num_signal_samples=num_noise_samples, noise_path_save=noise_save_path, \\\n",
    "                 n_fft=400, win_length=400, hop_len=200, f_min=0, f_max=8000, \\\n",
    "                 perform_stft=True, normalize=True, default_sr=16000, sec=6, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "shuffle = True\n",
    "num_workers = 12\n",
    "# data_loader = DataLoader(signal_synthesis_dataset, batch_size=BATCH_SIZE, shuffle=shuffle, num_workers=num_workers)\n",
    "data_loader = DataLoader(signal_synthesis_dataset, batch_size=BATCH_SIZE, shuffle=shuffle, num_workers=num_workers)\n",
    "# data_loader.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building\n",
    "# class BiDirectLSTM(nn.Module):\n",
    "#     def __init__(self, rnn_dim, hidden_size, dropout, batch_first=True):\n",
    "#         super(BiLSTM, self).__init__()\n",
    "        \n",
    "#         self.BiLSTM = nn.LSTM(\n",
    "#                 input_size=rnn_dim,\n",
    "#                 hidden_size=hidden_size,\n",
    "#                 num_layers=2, batch_first=batch_first, bidirectional=True)\n",
    "#         self.layer_norm = nn.LayerNorm(rnn_dim)\n",
    "#         self.dropout(dropout)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.layer_norm(x)\n",
    "#         x = F.gelu(x)\n",
    "#         x, _ = self.BiLSTM(x)\n",
    "#         x = self.dropout(x)\n",
    "#         return x\n",
    "        \n",
    "\n",
    "\n",
    "class NoiseReducer(nn.Module):\n",
    "    def __init__(self, default_sr, n_fft, win_length, hop_len, f_min, f_max, dropout=0.5, batch_first=True, stride=2, normalized=True):\n",
    "        super(NoiseReducer, self).__init__()\n",
    "        \n",
    "        self.n_fft = n_fft\n",
    "        self.win_length = win_length\n",
    "        self.hop_len = hop_len\n",
    "        self.f_min = f_min\n",
    "        self.f_max = f_max\n",
    "        self.normalized = normalized\n",
    "        \n",
    "        # LSTM UNITS\n",
    "        self.rnn_dims = n_fft//2 + 1\n",
    "        self.num_layers = 4\n",
    "        self.batch_first = True\n",
    "        self.dropout = 0.2\n",
    "        self.bidir = True\n",
    "\n",
    "        \n",
    "        \n",
    "        self.bilstm1 = nn.LSTM(input_size=self.rnn_dims, hidden__state=self.rnn_dims, num_layers=4, batch_first=self.batch_first, dropout=self.dropout, bidirectional=self.bidir)\n",
    "        self.bilstm2 = nn.LSTM(input_size=self.rnn_dims, hidden__state=self.rnn_dims, num_layers=4, batch_first=self.batch_first, dropout=self.dropout, bidirectional=self.bidir)\n",
    "        self.dense1 = nn.Linear()\n",
    "        \n",
    "    def forward(self, inp_tensor):\n",
    "        inp_tensor = inp_tensor.permute(0, 2, 1)\n",
    "        x, h_n, c_n = self.bilstm1(inp_tensor)\n",
    "        x, h_n, c_n = self.bilstm2(x, h_n, c_n)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_layer = nn.Linear(128, 64)\n",
    "inp = torch.randn((4, 5, 128))\n",
    "out = lin_layer(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "96000/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_synthesis_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# data_loader_iter = iter(data_loader)\n",
    "for index, i in enumerate(data_loader):\n",
    "#     i = next(data_loader)\n",
    "    print(i[0].shape, index)\n",
    "    if index < 2000:\n",
    "        continue\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i[0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = data_loader.__iter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
