{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio as ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta.set_audio_backend(\"sox_io\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd.profiler as profiler\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "import glob\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from python_files.Noise_Reduction_Datagen_paths import Signal_Synthesis_DataGen\n",
    "from python_files.unet_basic import Model\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *\n",
    "from fastai.data.core import DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(dir_path):\n",
    "    paths = []\n",
    "    for root, dirs, files in os.walk(dir_path):\n",
    "        for name in files:\n",
    "            if name.endswith(\".wav\") or name.endswith(\".mp3\"):\n",
    "                paths.append(os.path.join(root, name))\n",
    "    paths = np.asarray(paths)\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_paths = np.load(\"./dataset_loader_files/signal_paths_nums_save.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "noise_paths = get_paths(\"./dataset/UrbanSound8K-Resampled/\")[:1000]\n",
    "signal_paths = np.load(\"./dataset_loader_files/signal_paths_nums_save.npy\")[:500]\n",
    "signal_dir = \"./dataset/cv-corpus-5.1-2020-06-22-Resampled/en/clips/\"\n",
    "noise_save_path = \"\"#\"./dataset_loader_files/noise_paths_resampled_save.npy\"\n",
    "train = True\n",
    "n_fft=1024\n",
    "win_length=n_fft\n",
    "hop_len=n_fft//4\n",
    "create_specgram = False\n",
    "perform_stft = False\n",
    "default_sr = 16000\n",
    "sec = (16384/default_sr)*2\n",
    "augment=True\n",
    "device_datagen = \"cpu\"\n",
    "\n",
    "train_ds = Signal_Synthesis_DataGen(noise_paths, signal_paths, signal_dir, \\\n",
    "                 n_fft=n_fft, win_length=win_length, hop_len=hop_len, create_specgram=create_specgram, \\\n",
    "                 perform_stft=perform_stft, normalize=True, default_sr=default_sr, sec=sec, epsilon=1e-5, augment=False, device=device_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "noise_paths = get_paths(\"./dataset/UrbanSound8K-Resampled/\")[5000:5100]\n",
    "signal_paths = np.load(\"./dataset_loader_files/signal_paths_nums_save.npy\")[6000:6100]\n",
    "signal_dir = \"./dataset/cv-corpus-5.1-2020-06-22-Resampled/en/clips/\"\n",
    "noise_save_path = \"\"#\"./dataset_loader_files/noise_paths_resampled_save.npy\"\n",
    "train = False\n",
    "\n",
    "val_ds = Signal_Synthesis_DataGen(noise_paths, signal_paths, signal_dir,\\\n",
    "                 n_fft=n_fft, win_length=win_length, hop_len=hop_len, create_specgram=create_specgram, \\\n",
    "                 perform_stft=perform_stft, normalize=True, default_sr=default_sr, sec=sec, epsilon=1e-5, augment=False, device=device_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BATCH_SIZE = 52\n",
    "shuffle = True\n",
    "num_workers = 7\n",
    "pin_memory = False\n",
    "\n",
    "tr_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=shuffle, num_workers=num_workers)\n",
    "val_loader= DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=shuffle, num_workers=num_workers, pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mod_MSELoss(nn.Module):\n",
    "    def __init__(self, mul_factor):\n",
    "        super(Mod_MSELoss, self).__init__()\n",
    "        self.loss_fn = nn.MSELoss(reduction=\"mean\")\n",
    "        self.mul_factor = mul_factor\n",
    "        \n",
    "        \n",
    "    def forward(self, sig_pred, sig_true):\n",
    "        loss = self.loss_fn(sig_pred, sig_true)\n",
    "        loss = self.mul_factor*loss\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSamplingLayer(nn.Module):\n",
    "    def __init__(self, channel_in, channel_out, dilation=1, kernel_size=15, stride=1, padding=7):\n",
    "        super(DownSamplingLayer, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv1d(channel_in, channel_out, kernel_size=kernel_size,\n",
    "                      stride=stride, padding=padding, dilation=dilation),\n",
    "            nn.BatchNorm1d(channel_out),\n",
    "            nn.LeakyReLU(negative_slope=0.1)\n",
    "        )\n",
    "\n",
    "    def forward(self, ipt):\n",
    "        return self.main(ipt)\n",
    "\n",
    "class UpSamplingLayer(nn.Module):\n",
    "    def __init__(self, channel_in, channel_out, kernel_size=5, stride=1, padding=2):\n",
    "        super(UpSamplingLayer, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv1d(channel_in, channel_out, kernel_size=kernel_size,\n",
    "                      stride=stride, padding=padding),\n",
    "            nn.BatchNorm1d(channel_out),\n",
    "            nn.LeakyReLU(negative_slope=0.1, inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, ipt):\n",
    "        return self.main(ipt)\n",
    "\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(self, n_layers=12, channels_interval=24):\n",
    "        super(Model, self).__init__()\n",
    "        self.loss_fn = Mod_MSELoss(mul_factor=1000)\n",
    "        self.n_layers = n_layers\n",
    "        self.channels_interval = channels_interval\n",
    "        encoder_in_channels_list = [1] + [i * self.channels_interval for i in range(1, self.n_layers)]\n",
    "        encoder_out_channels_list = [i * self.channels_interval for i in range(1, self.n_layers + 1)]\n",
    "\n",
    "        #          1    => 2    => 3    => 4    => 5    => 6   => 7   => 8   => 9  => 10 => 11 =>12\n",
    "        # 16384 => 8192 => 4096 => 2048 => 1024 => 512 => 256 => 128 => 64 => 32 => 16 =>  8 => 4\n",
    "        self.encoder = nn.ModuleList()\n",
    "        for i in range(self.n_layers):\n",
    "            self.encoder.append(\n",
    "                DownSamplingLayer(\n",
    "                    channel_in=encoder_in_channels_list[i],\n",
    "                    channel_out=encoder_out_channels_list[i]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.middle = nn.Sequential(\n",
    "            nn.Conv1d(self.n_layers * self.channels_interval, self.n_layers * self.channels_interval, 15, stride=1,\n",
    "                      padding=7),\n",
    "            nn.BatchNorm1d(self.n_layers * self.channels_interval),\n",
    "            nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "        )\n",
    "\n",
    "        decoder_in_channels_list = [(2 * i + 1) * self.channels_interval for i in range(1, self.n_layers)] + [\n",
    "            2 * self.n_layers * self.channels_interval]\n",
    "        decoder_in_channels_list = decoder_in_channels_list[::-1]\n",
    "        decoder_out_channels_list = encoder_out_channels_list[::-1]\n",
    "        self.decoder = nn.ModuleList()\n",
    "        for i in range(self.n_layers):\n",
    "            self.decoder.append(\n",
    "                UpSamplingLayer(\n",
    "                    channel_in=decoder_in_channels_list[i],\n",
    "                    channel_out=decoder_out_channels_list[i]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv1d(1 + self.channels_interval, 1, kernel_size=1, stride=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        tmp = []\n",
    "        o = input\n",
    "\n",
    "        # Up Sampling\n",
    "        for i in range(self.n_layers):\n",
    "            o = self.encoder[i](o)\n",
    "#             print(o.shape)\n",
    "            tmp.append(o)\n",
    "            # [batch_size, T // 2, channels]\n",
    "            o = o[:, :, ::2]\n",
    "\n",
    "        o = self.middle(o)\n",
    "\n",
    "        # Down Sampling\n",
    "        for i in range(self.n_layers):\n",
    "            # [batch_size, T * 2, channels]\n",
    "            o = F.interpolate(o, scale_factor=2, mode=\"linear\", align_corners=True)\n",
    "            # Skip Connection\n",
    "            # print(o.shape, len(tmp))\n",
    "            o = torch.cat([o, tmp[self.n_layers - i -1]], dim=1)\n",
    "            o = self.decoder[i](o)\n",
    "\n",
    "        o = torch.cat([o, input], dim=1)\n",
    "        o = self.out(o)\n",
    "        return o\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x.unsqueeze(dim=1).to(device))\n",
    "        loss = self.loss_fn(y_pred, y.unsqueeze(dim=1))\n",
    "\n",
    "        return loss\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x.unsqueeze(dim=1).to(device))\n",
    "        \n",
    "        loss = self.loss_fn(y_pred, y.unsqueeze(dim=1))\n",
    "        self.log(\"val_loss\", loss, enable_graph=True, on_epoch=True, prog_bar=True)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=0.001, weight_decay=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Primary model\n"
     ]
    }
   ],
   "source": [
    "use_scripted_model = False\n",
    "w_decay = 1e-4\n",
    "\n",
    "if not use_scripted_model:\n",
    "    print(\"Using Primary model\")\n",
    "    model = Model()#NoiseReducer(default_sr=default_sr, n_fft=n_fft, win_length=win_length, hop_len=hop_len, sec=sec).to(device)\n",
    "#     model.to(device)\n",
    "else:\n",
    "    print(\"Using Scripted Model\")\n",
    "    model = scripted_model\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0)\n",
    "criterion = Mod_MSELoss(mul_factor=1000)\n",
    "n_epochs=100\n",
    "\n",
    "\n",
    "model.train()\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
