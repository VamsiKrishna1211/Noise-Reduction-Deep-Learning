{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import librosa\n",
    "import torchaudio as ta\n",
    "ta.set_audio_backend(\"sox_io\")\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd.profiler as profiler\n",
    "# import pytorch_lightning as pl\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "import glob\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from python_files.Noise_Reduction_Datagen_paths import Signal_Synthesis_DataGen\n",
    "# from python_files.unet_basic import Model\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import gc\n",
    "\n",
    "from random import shuffle\n",
    "import random\n",
    "\n",
    "# from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sox', 'sox_io']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ta.list_audio_backends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.callback.tensorboard import TensorBoardCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.8'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai\n",
    "\n",
    "fastai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8101"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.0a0+56b43f4'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce RTX 3090'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(dir_path):\n",
    "    paths = []\n",
    "    for root, dirs, files in os.walk(dir_path):\n",
    "        for name in files:\n",
    "            if name.endswith(\".wav\") or name.endswith(\".mp3\"):\n",
    "                paths.append(os.path.join(root, name))\n",
    "                \n",
    "    paths = np.asarray(paths)\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_paths = np.load(\"./dataset_loader_files/signal_paths_nums_save.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_paths_sh = get_paths(\"./dataset/Reduced_noise/\")\n",
    "shuffle(noise_paths_sh)\n",
    "\n",
    "signal_paths_sh = get_paths(\"./dataset/Reduced_clean_signals/\")\n",
    "shuffle(signal_paths_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1741,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_paths_sh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10785.84"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(51855 * 104 )/ 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_paths_sh[-500:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_paths = np.load(\"./dataset_loader_files/signal_paths_nums_save.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 ./dataset/Reduced_clean_signals/common_voice_en_19355404.mp3\n"
     ]
    }
   ],
   "source": [
    "noise_paths = noise_paths_sh[0:150]\n",
    "signal_paths = signal_paths_sh[:150]\n",
    "signal_dir = \"\"#\"./dataset/cv-corpus-5.1-2020-06-22-Resampled/en/clips\"\n",
    "noise_save_path = \"\"#\"./dataset_loader_files/noise_paths_resampled_save.npy\"\n",
    "train = True\n",
    "n_fft=1024\n",
    "win_length=n_fft\n",
    "hop_len=n_fft//4\n",
    "create_specgram = False\n",
    "perform_stft = False\n",
    "normalize = True\n",
    "default_sr = 16000\n",
    "sec = (16384/default_sr)*8\n",
    "augment=True\n",
    "device_datagen = \"cpu\"\n",
    "\n",
    "train_ds = Signal_Synthesis_DataGen(noise_paths, signal_paths, signal_dir, \\\n",
    "                 n_fft=n_fft, win_length=win_length, hop_len=hop_len, create_specgram=create_specgram, \\\n",
    "                 perform_stft=perform_stft, normalize=normalize, default_sr=default_sr, sec=sec, epsilon=1e-5, augment=False, device=device_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 ./dataset/Reduced_clean_signals/common_voice_en_19670366.mp3\n"
     ]
    }
   ],
   "source": [
    "noise_paths = noise_paths_sh[100:150]\n",
    "signal_paths = signal_paths_sh[1000:1050]\n",
    "signal_dir = \"\"#\"./dataset/cv-corpus-5.1-2020-06-22-Resampled/en/clips\"\n",
    "noise_save_path = \"\"#\"./dataset_loader_files/noise_paths_resampled_save.npy\"\n",
    "train = False\n",
    "\n",
    "val_ds = Signal_Synthesis_DataGen(noise_paths, signal_paths, signal_dir,\\\n",
    "                 n_fft=n_fft, win_length=win_length, hop_len=hop_len, create_specgram=create_specgram, \\\n",
    "                 perform_stft=perform_stft, normalize=normalize, default_sr=default_sr, sec=sec, epsilon=1e-5, augment=False, device=device_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000e-05)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.__getitem__(1)[0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BATCH_SIZE = 78\n",
    "shuffle = True\n",
    "num_workers = 12\n",
    "pin_memory = True\n",
    "\n",
    "# data_loader = DataLoader(signal_synthesis_dataset, batch_size=BATCH_SIZE, shuffle=shuffle, num_workers=num_workers)\n",
    "# data_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=shuffle, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "dls = DataLoaders.from_dsets(train_ds, val_ds, bs=BATCH_SIZE, num_workers=num_workers, pin_memory=pin_memory).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unsqueezer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Unsqueezer, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x.usqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.after_batch = Unsqueezer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 1 µs, total: 1 µs\n",
      "Wall time: 2.62 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# for data in dls.train:\n",
    "#     print(data[0].max(), data[0].min())\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-8f1abbd1487a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data[1].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22500"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Negative_SNR_Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Negative_SNR_Loss, self).__init__()\n",
    "    \n",
    "    def forward(self, sig_pred, sig_true):\n",
    "        \n",
    "        sig_true_sq = torch.square(sig_true)\n",
    "        sig_pred_sq = torch.square(sig_true - sig_pred)\n",
    "\n",
    "        sig_true_mean = torch.mean(sig_true_sq)\n",
    "        sig_pred_mean = torch.mean(sig_pred_sq)\n",
    "\n",
    "        snr = sig_true_mean / sig_pred_mean + 1e-7\n",
    "        loss = -1*torch.log10(snr)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mod_MSELoss(nn.Module):\n",
    "    def __init__(self, mul_factor):\n",
    "        super(Mod_MSELoss, self).__init__()\n",
    "        self.loss_fn = nn.MSELoss(reduction=\"mean\")\n",
    "        self.mul_factor = mul_factor\n",
    "        \n",
    "        \n",
    "    def forward(self, sig_pred, sig_true):\n",
    "        loss = self.loss_fn(sig_pred, sig_true)\n",
    "        loss = self.mul_factor*loss\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSamplingLayer(nn.Module):\n",
    "    def __init__(self, channel_in, channel_out, dilation=1, kernel_size=15, stride=1, padding=7):\n",
    "        super(DownSamplingLayer, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv1d(channel_in, channel_out, kernel_size=kernel_size,\n",
    "                      stride=stride, padding=padding, dilation=dilation),\n",
    "            nn.BatchNorm1d(channel_out),\n",
    "#             nn.LeakyReLU(negative_slope=0.1)\n",
    "            nn.ELU()\n",
    "        )\n",
    "\n",
    "    def forward(self, ipt):\n",
    "        return self.main(ipt)\n",
    "\n",
    "class UpSamplingLayer(nn.Module):\n",
    "    def __init__(self, channel_in, channel_out, kernel_size=5, stride=1, padding=2):\n",
    "        super(UpSamplingLayer, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv1d(channel_in, channel_out, kernel_size=kernel_size,\n",
    "                      stride=stride, padding=padding),\n",
    "            nn.BatchNorm1d(channel_out),\n",
    "#             nn.LeakyReLU(negative_slope=0.1, inplace=True),\n",
    "            nn.ELU()\n",
    "        )\n",
    "\n",
    "    def forward(self, ipt):\n",
    "        return self.main(ipt)\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_layers=12, channels_interval=24):\n",
    "        super(Model, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.channels_interval = channels_interval\n",
    "        encoder_in_channels_list = [1] + [i * self.channels_interval for i in range(1, self.n_layers)]\n",
    "        encoder_out_channels_list = [i * self.channels_interval for i in range(1, self.n_layers + 1)]\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        #          1    => 2    => 3    => 4    => 5    => 6   => 7   => 8   => 9  => 10 => 11 =>12\n",
    "        # 16384 => 8192 => 4096 => 2048 => 1024 => 512 => 256 => 128 => 64 => 32 => 16 =>  8 => 4\n",
    "        self.encoder = nn.ModuleList()\n",
    "        for i in range(self.n_layers):\n",
    "            self.encoder.append(\n",
    "                DownSamplingLayer(\n",
    "                    channel_in=encoder_in_channels_list[i],\n",
    "                    channel_out=encoder_out_channels_list[i]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.middle = nn.Sequential(\n",
    "            nn.Conv1d(self.n_layers * self.channels_interval, self.n_layers * self.channels_interval, 15, stride=1,\n",
    "                      padding=7),\n",
    "            nn.BatchNorm1d(self.n_layers * self.channels_interval),\n",
    "#             nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "            nn.ELU(inplace=True)\n",
    "        )\n",
    "\n",
    "        decoder_in_channels_list = [(2 * i + 1) * self.channels_interval for i in range(1, self.n_layers)] + [\n",
    "            2 * self.n_layers * self.channels_interval]\n",
    "        decoder_in_channels_list = decoder_in_channels_list[::-1]\n",
    "        decoder_out_channels_list = encoder_out_channels_list[::-1]\n",
    "        self.decoder = nn.ModuleList()\n",
    "        for i in range(self.n_layers):\n",
    "            self.decoder.append(\n",
    "                UpSamplingLayer(\n",
    "                    channel_in=decoder_in_channels_list[i],\n",
    "                    channel_out=decoder_out_channels_list[i]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv1d(1 + self.channels_interval, 1, kernel_size=1, stride=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        tmp = []\n",
    "        o = input\n",
    "\n",
    "        # Up Sampling\n",
    "        for i in range(self.n_layers):\n",
    "            o = self.encoder[i](o)\n",
    "#             print(o.shape)\n",
    "            tmp.append(o)\n",
    "            # [batch_size, T // 2, channels]\n",
    "            o = o[:, :, ::2]\n",
    "\n",
    "        o = self.middle(o)\n",
    "\n",
    "        # Down Sampling\n",
    "        for i in range(self.n_layers):\n",
    "            # [batch_size, T * 2, channels]\n",
    "            o = F.interpolate(o, scale_factor=2, mode=\"linear\", align_corners=True)\n",
    "            # Skip Connection\n",
    "            # print(o.shape, len(tmp))\n",
    "            o = torch.cat([o, tmp[self.n_layers - i -1]], dim=1)\n",
    "            o = self.decoder[i](o)\n",
    "        o = torch.cat([o, input], dim=1)\n",
    "        o = self.out(o)\n",
    "#         o = torch.mul(o, input)\n",
    "#         o = self.sigmoid(o)\n",
    "        return o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Primary model\n"
     ]
    }
   ],
   "source": [
    "use_scripted_model = False\n",
    "w_decay = 1e-4\n",
    "\n",
    "if not use_scripted_model:\n",
    "    print(\"Using Primary model\")\n",
    "    model = Model(12, 24)#NoiseReducer(default_sr=default_sr, n_fft=n_fft, win_length=win_length, hop_len=hop_len, sec=sec).to(device)\n",
    "    model.to(device)\n",
    "else:\n",
    "    print(\"Using Scripted Model\")\n",
    "    model = torch.jit.script(Model())\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0)\n",
    "criterion = Mod_MSELoss(mul_factor=1000)\n",
    "n_epochs=100\n",
    "\n",
    "\n",
    "model.train()\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, loss_func=criterion, model_dir=\"./Model_saves/\", \\\n",
    "                cbs=[ShowGraphCallback(), SaveModelCallback(monitor='valid_loss', fname='bestmodel', every_epoch=False)]).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.load(\"bestmodel_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Model (Input shape: 78)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     78 x 24 x 131072    \n",
       "Conv1d                                    384        True      \n",
       "BatchNorm1d                               48         True      \n",
       "ELU                                                            \n",
       "____________________________________________________________________________\n",
       "                     78 x 48 x 65536     \n",
       "Conv1d                                    17328      True      \n",
       "BatchNorm1d                               96         True      \n",
       "ELU                                                            \n",
       "____________________________________________________________________________\n",
       "                     78 x 72 x 32768     \n",
       "Conv1d                                    51912      True      \n",
       "BatchNorm1d                               144        True      \n",
       "ELU                                                            \n",
       "____________________________________________________________________________\n",
       "                     78 x 96 x 16384     \n",
       "Conv1d                                    103776     True      \n",
       "BatchNorm1d                               192        True      \n",
       "ELU                                                            \n",
       "____________________________________________________________________________\n",
       "                     78 x 120 x 8192     \n",
       "Conv1d                                    172920     True      \n",
       "BatchNorm1d                               240        True      \n",
       "ELU                                                            \n",
       "____________________________________________________________________________\n",
       "                     78 x 144 x 4096     \n",
       "Conv1d                                    259344     True      \n",
       "BatchNorm1d                               288        True      \n",
       "ELU                                                            \n",
       "____________________________________________________________________________\n",
       "                     78 x 168 x 2048     \n",
       "Conv1d                                    363048     True      \n",
       "BatchNorm1d                               336        True      \n",
       "ELU                                                            \n",
       "____________________________________________________________________________\n",
       "                     78 x 192 x 1024     \n",
       "Conv1d                                    484032     True      \n",
       "BatchNorm1d                               384        True      \n",
       "ELU                                                            \n",
       "____________________________________________________________________________\n",
       "                     78 x 216 x 512      \n",
       "Conv1d                                    622296     True      \n",
       "BatchNorm1d                               432        True      \n",
       "ELU                                                            \n",
       "____________________________________________________________________________\n",
       "                     78 x 240 x 256      \n",
       "Conv1d                                    777840     True      \n",
       "BatchNorm1d                               480        True      \n",
       "ELU                                                            \n",
       "____________________________________________________________________________\n",
       "                     78 x 264 x 128      \n",
       "Conv1d                                    950664     True      \n",
       "BatchNorm1d                               528        True      \n",
       "ELU                                                            \n",
       "____________________________________________________________________________\n",
       "                     78 x 288 x 64       \n",
       "Conv1d                                    1140768    True      \n",
       "BatchNorm1d                               576        True      \n",
       "ELU                                                            \n",
       "Conv1d                                    1244448    True      \n",
       "BatchNorm1d                               576        True      \n",
       "ELU                                                            \n",
       "____________________________________________________________________________\n",
       "                     78 x 288 x 64       \n",
       "Conv1d                                    829728     True      \n",
       "BatchNorm1d                               576        True      \n",
       "ELU                                                            \n",
       "____________________________________________________________________________\n",
       "                     78 x 264 x 128      \n",
       "Conv1d                                    728904     True      \n",
       "BatchNorm1d                               528        True      \n",
       "ELU                                                            \n",
       "____________________________________________________________________________\n",
       "                     78 x 240 x 256      \n",
       "Conv1d                                    605040     True      \n",
       "BatchNorm1d                               480        True      \n",
       "ELU                                                            \n",
       "____________________________________________________________________________\n",
       "                     78 x 216 x 512      \n",
       "Conv1d                                    492696     True      \n",
       "BatchNorm1d                               432        True      \n",
       "ELU                                                            \n",
       "____________________________________________________________________________\n",
       "                     78 x 192 x 1024     \n",
       "Conv1d                                    391872     True      \n",
       "BatchNorm1d                               384        True      \n",
       "ELU                                                            \n",
       "____________________________________________________________________________\n",
       "                     78 x 168 x 2048     \n",
       "Conv1d                                    302568     True      \n",
       "BatchNorm1d                               336        True      \n",
       "ELU                                                            \n",
       "____________________________________________________________________________\n",
       "                     78 x 144 x 4096     \n",
       "Conv1d                                    224784     True      \n",
       "BatchNorm1d                               288        True      \n",
       "ELU                                                            \n",
       "____________________________________________________________________________\n",
       "                     78 x 120 x 8192     \n",
       "Conv1d                                    158520     True      \n",
       "BatchNorm1d                               240        True      \n",
       "ELU                                                            \n",
       "____________________________________________________________________________\n",
       "                     78 x 96 x 16384     \n",
       "Conv1d                                    103776     True      \n",
       "BatchNorm1d                               192        True      \n",
       "ELU                                                            \n",
       "____________________________________________________________________________\n",
       "                     78 x 72 x 32768     \n",
       "Conv1d                                    60552      True      \n",
       "BatchNorm1d                               144        True      \n",
       "ELU                                                            \n",
       "____________________________________________________________________________\n",
       "                     78 x 48 x 65536     \n",
       "Conv1d                                    28848      True      \n",
       "BatchNorm1d                               96         True      \n",
       "ELU                                                            \n",
       "____________________________________________________________________________\n",
       "                     78 x 24 x 131072    \n",
       "Conv1d                                    8664       True      \n",
       "BatchNorm1d                               48         True      \n",
       "ELU                                                            \n",
       "____________________________________________________________________________\n",
       "                     78 x 1 x 131072     \n",
       "Conv1d                                    26         True      \n",
       "Sigmoid                                                        \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 10,132,802\n",
       "Total trainable params: 10,132,802\n",
       "Total non-trainable params: 0\n",
       "\n",
       "Optimizer used: <function Adam at 0x7f5135214310>\n",
       "Loss function: Mod_MSELoss(\n",
       "  (loss_fn): MSELoss()\n",
       ")\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - MixedPrecision\n",
       "  - Recorder\n",
       "  - ProgressCallback\n",
       "  - SaveModelCallback\n",
       "  - ShowGraphCallback"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'GeForce RTX 3090'\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.06309573650360108, lr_steep=1.0964781722577754e-06)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEKCAYAAAAVaT4rAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAArkElEQVR4nO3dd3yV9f3+8dc7k4QAARIQCHvIXoY9RNS6EFC01apFxYGbatX6bfvTtlpXq9ZRFReoKFWk7lkLsoWEvfcIMsIKhJGQ5PP7I4dKMRNyn3k9H4/z4Jz7nPvcVyBcufO57/O5zTmHiIhEjqhABxAREf9S8YuIRBgVv4hIhFHxi4hEGBW/iEiEUfGLiESYGK83YGbRQAaw1Tk3xMzGAWcCOb6XXOucW1jWe6SkpLhmzZp5GVNEJOxkZmbucs6lnrjc8+IH7gJWADWPW3avc25SRd+gWbNmZGRkVHkwEZFwZmabSlru6VCPmaUBFwGverkdERGpOK/H+J8B7gOKTlj+iJktNrOnzSy+pBXN7CYzyzCzjOzsbI9jiohEDs+K38yGADudc5knPPUA0BboAdQB7i9pfefcWOdcunMuPTX1J0NUIiJykrzc4+8HDDWzjcBEYLCZve2c2+aK5QFvAD09zCAiIifwrPidcw8459Kcc82AK4D/OOeuNrMGAGZmwHBgqVcZRETkp/xxVs+JJphZKmDAQmB0ADKIiEQsvxS/c24qMNV3f7A/tlmSo4VF7DmYT/aBPPYczKd9w5qkJJV4bFlEJGwFYo8/INbuzGXIc9M5cvTHE4xqVIvh/y5sxxU9GlM88iQiEv4ipvj/vWIHR44W8eDF7WlQqxrV42N4YcpaHpi8hA8XbOXRSzvRIjUp0DFFRDwXMcU/c+0u2tRP4rp+zf+7rH+rFP45bwuPfL6Cn788m9kPnE1stKYvEpHwFhEtl1dQyLyNe+jbMuV/lpsZV/RswpOXdWFXbj7zNu4JUEIREf+JiOJfsHkfR44W0bdl3RKfH9A6hbjoKL5dsdPPyURE/C8iin/W2l1EGfRqUXLxV4+PoU/LuvxnpYpfRMJfRBT/zHW76ZSWTK2E2FJfc3a7emzYdZD12bl+TCYi4n9hX/y5eQUs2rKPfqUM8xwzuG09AO31i0jYC/vin7thNwVFjn6tUsp8XVrtRNqeVoN/r9jhp2QiIoER9sU/a+1u4mKiOKNp7XJfO7htPeZt3EvO4aN+SCYiEhhhX/wz1+0mvWltqsVGl/vas9vVo7DIMW215v8XkfAV1sW/OzePFdv2lzvMc0zXxrWpUz1O4/wiEtbCuvhnr98NUOr5+yeKjjIGnZ7KlFU7KSg88aJhVWNXbh77j2goSUQCJ6yLf+ba3dSIj6FTo1oVXufstvXZd+goGZv2ntQ2D+UXcO/7i+jxyL/54yfL2LT7IABb9hzigclL6PPot1w5dg6FRe6k3l9E5FSF9Vw9t5zZkp+1r09MJebfOattKknxMbyXsYXepXzgqzRrd+Zy64RM1uzMpX+rFN6es4lxszbStXEyS7JyiDKjf6sUpqzKZsL3m/hVn2b/s/7m3YdIq51AVJRmChUR74T1Hn+Tuomc5Ts/v6IS42IY3q0hny3eRs6hig/JfL5kG8Oen8Gu3HzevL4nb43qxcz7B3PH4NYczCvg6t5NmXbfWbx+bQ/6t0rhya9WkX0g77/rT5y7mYFPTuH5KWsrlVdEpLLCuvhP1pU9m5BXUMTkBVkVev3nS7Zx+zvzOf20Gnx2Z38GtC6+OHy9mtW4+9w2fP3rM3loaAdOq1UNM+OhoR04crSQx75YCcBni7fxwL+WEBcTxSvT1rP3YL5nX5uIiIq/BB0a1qJL42TenbsZ58oei5+6aid3TVxA9ya1efuGXjSolVDu+7eql8QNA1rwwfwsnv12DWP+uYD0prV57+Y+5OYXMHb6+qr6UkREfkLFX4pf9mzM6h25ZJZxkHfuhj2MfjuT1vVq8Nq1PUiMq/ghkzsGt6JhrWo89c1qWterwasje9C1cTIXd27IuJkb2ZWbV/6biIicBBV/KYZ0bkhSfAzvzN1c4vNrdx5g1Lh5NExO4M1RPcucAK4kiXExPHFZF85pV4/x1/+4/phzWpNXUMiLU9ed8tcgIlISFX8pqseXfpD3UH4Bt06YT2xMFG+P6nXSF2zv3zqFV0f2ILXGj+u3SE1iRPc03pqzie05R3DOsedgPht3HfTsswUiElk8P53TzKKBDGCrc26ImTUHJgJ1gUzgGudcUB7NvLJnE96es5nXZ25gzDmt/3tB9v/30TLW7Mxl/HU9aZhc/ph+Zd15dms+XLiVIc9N52BeIYePFgIQFx1Fi9TqtGtQk1+f04YmdROrfNsiEv78cR7/XcAKoKbv8ePA0865iWb2EjAKeNEPOSqtQ8NanHV6Kn//dg2Ls/bxp2EdmbN+N5Mys7hjcCsGtkn1ZLuN6yTyuwvbMXv9btJqJ9IoOYGkajGsy85l9fYDfLVsOxt3H+SD0X11zr+IVJqVd9bKKb25WRowHngEuBu4GMgGTnPOFZhZH+Ah59x5Zb1Penq6y8jI8CxnWQoKixg3ayNPfbMa58Dh6No4mQk39CY6QKX7QWYW97y/iEcu6chVvZoGJIOIBD8zy3TOpZ+43Osx/meA+4Bjg9N1gX3OuQLf4yygUUkrmtlNZpZhZhnZ2YGbLTMmOoobBrTgm7vPpF+rFFJrxPPsFd0CVvoAl3ZvRJ8WdXn8i5X/8yEwEZGK8Kz4zWwIsNM5l3ky6zvnxjrn0p1z6amp3gypVEaj5AReHZnOtHvPol7NagHNYmY8fElHjhwt4pHPlgc0i4iEHi/3+PsBQ81sI8UHcwcDfweSzezYsYU0YKuHGarcsQO8gdYyNYnRg1ry4cIfmLFmV6DjiEgI8az4nXMPOOfSnHPNgCuA/zjnrgKmAJf5XjYS+MirDOHu1kEtaZ5Snd99uIRD+QXlryAiQmDO478fuNvM1lI85v9aADKEhWqx0Tx2aSc27T7EE1+uCnQcEQkRfpmW2Tk3FZjqu78e6OmP7UaCXi3qcl2/ZrwxcyPndTiNPhW86IyIRC59cjcM3HdeW5rVTeTeSYvIzdOQj4iUTcUfBhLiovnr5V3Yuu8wj36+ItBxRCTIqfjDRHqzOtzQvzkTvt/M7HW7Ax1HRIKYij+M3H3u6TSuk8Dv/rWEI775fURETqTiDyMJcdE8MrwT63cd5B+a1llESqHiDzMD26QyrGtDXpy6lrU7DwQ6jogEIRV/GPrDkPYkxsXwf5OXUlTk3SR8IhKaVPxhKCUpnt9d2I65G/fw2owNgY4jIkFGxR+mLk9P4/wOp/HI5yv4aGFITYckIh5T8YcpM+OZK7rSq3kd7nlvEd+tDtzU1iISXFT8YaxabDSvjEyndf0ajH4rkwWb9wY6kogEARV/mKtZLZbx1xdf0P26cfNYuX1/oCOJSICp+CNAvRrVmHBDL+Jjorj61bmsz84NdCQRCSAVf4RoXCeRCTf0xjnH1a9+T9beQ4GOJCIBouKPIK3qJfHmqJ7k5hVw1avfk3PoaKAjiUgAqPgjTIeGtXjjuh5k7T3MY1+uDHQcEQkAFX8EOqNpHUb1b867czczd8OeQMcRET9T8UeoMee0Jq12Ag9MXkxegWbyFIkkKv4IlRgXw8PDO7Iu+yAvaiZPkYii4o9gg06vx7CuDfnHlHWayVMkgqj4I9wfhrSnWmwUD3+mSzaKRArPit/MqpnZXDNbZGbLzOyPvuXjzGyDmS303bp6lUHKl5IUz+2DWzF1VTYz1+4KdBwR8QMv9/jzgMHOuS5AV+B8M+vte+5e51xX322hhxmkAn7VpxmNkhN49IsVmr9fJAJ4Vvyu2LG5AWJ9N7VKEKoWG809P2vD0q37+WTxD4GOIyIe83SM38yizWwhsBP4xjn3ve+pR8xssZk9bWbxpax7k5llmFlGdramFPba8K6NaNegJk9+tUqnd4qEOU+L3zlX6JzrCqQBPc2sI/AA0BboAdQB7i9l3bHOuXTnXHpqaqqXMQWIijIeuKAtWXsP8/aczYGOIyIe8stZPc65fcAU4Hzn3DbfMFAe8AbQ0x8ZpHwD26QyoHUKz/x7NdtyDgc6joh4xMuzelLNLNl3PwE4F1hpZg18ywwYDiz1KoNU3p+HdaSg0HH/B0twTodkRMKRl3v8DYApZrYYmEfxGP+nwAQzWwIsAVKAhz3MIJXULKU6v72gLdNWZzNx3pZAxxERD8R49cbOucVAtxKWD/Zqm1I1rundlC+XbufhT5czoHUKabUTAx1JRKqQPrkrPxEVZTxxWWcA7pu0WOf2i4QZFb+UqHGdRH4/pD2z1u3mlenrAx1HRKqQil9KdUWPxlzY6TSe+GoVmZs0b79IuFDxS6nMjMdGdKZRcgK3v7OAvQfzAx1JRKqAil/KVLNaLC/8sju7c/O5+72FGu8XCQMqfilXp7Ra/H5IO6asyualabpoi0ioU/FLhVzTuykXdW7AX79axax1mr5ZJJSp+KVCzIzHR3SmWUp17nx3AdtzjgQ6koicJBW/VFhSfAwvX30Gh/ILue2d+RwtLAp0JBE5CSp+qZTW9Wvw2IjOZG7ay8OfLtd8PiIhyLMpGyR8De3SkEVb9vHajA0kVYvhNz87neI590QkFKj45aT87sJ2HMov4IUpxWf5qPxFQoeKX05KVJTxyPBOOAcvTFmHYdzzszYqf5EQoOKXkxYVZfzlkk4APD9lLUcLi/jtBW1V/iJBTsUvp+RY+cdGR/HytPUczC/gT0M7EhWl8hcJVip+OWVRUcafhnUgMT6al79bz6H8Qp4Y0ZmYaJ00JhKMVPxSJcyM357flqS4GP72zWoSYqN5xDcMJCLBRcUvVcbMuOPs1uTmFfDytPX0b5XCBZ0aBDqWiJxAv4tLlfvNeafTpXEy93+wmKy9hwIdR0ROoOKXKhcbHcVzV3SjyMGYiQsp0NQOIkFFxS+eaFI3kUcu6UjGpr08/uVKCjWPv0jQ8Kz4zayamc01s0VmtszM/uhb3tzMvjeztWb2TzOL8yqDBNawro24okdjXpm+gfOfmcaXS7drbh+RIODlHn8eMNg51wXoCpxvZr2Bx4GnnXOtgL3AKA8zSIA9emknXryqO4XOMfrtTIb/YxZb9mjcXySQPCt+VyzX9zDWd3PAYGCSb/l4YLhXGSTwzIwLOjXg6zEDeWJEZzZk53LlK3N00FckgDwd4zezaDNbCOwEvgHWAfuccwW+l2QBjUpZ9yYzyzCzjOzsbC9jih/EREfx8x6NmXBDb3IOH+XKV+bww77DgY4lEpE8LX7nXKFzriuQBvQE2lZi3bHOuXTnXHpqaqpXEcXPOqXV4u1Rvdh3sLj8t+Wo/EX8zS9n9Tjn9gFTgD5Aspkd++BYGrDVHxkkeHRpnMz4UT3ZnZvPlWPn6DKOIn7m5Vk9qWaW7LufAJwLrKD4B8BlvpeNBD7yKoMEr+5NajP++p7sys3nirGztecv4kde7vE3AKaY2WJgHvCNc+5T4H7gbjNbC9QFXvMwgwSxM5r+WP5XjtWwj4i/WCicV52enu4yMjICHUM8Mn/zXka+NpdaibG8fM0ZdGhYK9CRRMKCmWU659JPXK5P7krAdW9Smwk39qKg0HHpP2bx3rwtgY4kEtYqVPxmVt3Monz325jZUDOL9TaaRJLOacl8emd/0pvV5r4PFvOb9xfx9bLtZGzcw7rsXM33I1KFKjTUY2aZwACgNjCT4jH7fOfcVd7GK6ahnshRWOR4+pvVPD9l7f8sb3taDf5xVXdapCYFKJlI6CltqKeixT/fOdfdzO4AEpxzT5jZQt85+p5T8UeenQeOsCMnjz2H8tmy5xB/+3oV+QVFPDqiM0O7NAx0PJGQUFrxV/RCLGZmfYCr+HFuneiqCidyono1qlGvRrX/Ph7cth53vLuAO99dwNwNu3no4g66tKPISaro/5wxwAPAv5xzy8ysBcXn44v4RcPkBCbe1JubB7bg7Tmbuf2dBeQVFAY6lkhIqvTpnL6DvEnOuf3eRPopDfXI8V6bsYE/f7qcM9uk8tLVZ5AQp18+RUpySqdzmtk7ZlbTzKoDS4HlZnZvVYcUqYhR/Zvz+IhOTFuTzcg35pKbV1D+SiLyXxUd6mnv28MfDnwBNAeu8SqUSHl+0aMJz17RjcxNe7n9nfk63VOkEipa/LG+8/aHAx87545SPLe+SMBc3KUhfxrWgamrsnn4sxWBjiMSMip6Vs/LwEZgETDNzJoCfhvjFynNVb2asiH7IK/O2EDzlOqM7Nss0JFEgl6Fit859yzw7HGLNpnZWd5EEqmcBy5sx6Y9h/jjJ8tomJzAue3rBzqSSFCr6MHdWmb21LErYpnZ34DqHmcTqZDoKOPvV3SlY6Na3PxWBq9OX6+LuouUoaJj/K8DB4Cf+277gTe8CiVSWYlxMbx7Y2/ObV+fhz9bwW/eX8yRozrPX6QkFS3+ls65B51z6323PwItvAwmUlnV42N48aozGHNOaz6Yn8WVr8xhd25eoGOJBJ2KFv9hM+t/7IGZ9QN01QwJOlFRxphz2vDiVd1Z/sN+LntpNpt3Hwp0LJGgUtHiHw28YGYbzWwj8Dxws2epRE7RBZ0a8M6Nvdh7KJ9LX5zF0q05gY4kEjQqVPzOuUXOuS5AZ6Czc64bMNjTZCKn6IymdZg0ug/xMVH84uXZzFq3K9CRRIJCpaY3dM7tP26Onrs9yCNSpVrVq8HkW/vSqHYC170xj6mrdgY6kkjAncq8tlZlKUQ8VL9mNSbe1IeWqUnc9GYm3yzfEehIIgF1KsVf5onSZtbYzKaY2XIzW2Zmd/mWP2RmW81soe924SlkEKmQOtXjePfG3rRrWJNb3s7kg8wsnesvEavM4jezA2a2v4TbAaC8yyAVAPc459oDvYHbzKy977mnnXNdfbfPT/3LEClfrcRY3h7VkzOa1uae9xdx64T57NLpnhKByix+51wN51zNEm41nHNlTvfgnNvmnJvvu38AWAE0qrroIpVXo1osE27oxX3nn863K3bys6en8dnibYGOJeJXfrl2nZk1A7oB3/sW3W5mi83sdTOrXco6Nx2bIiI7O9sfMSVCxERHceugVnx6Z38a107gtnfm8+dPl2tqZ4kYnhe/mSUBHwBjfGcEvQi0BLoC24C/lbSec26scy7dOZeemprqdUyJQG3q1+CDW/pybd9mvDZjA9ePzyDn8NFAxxLxnKfF75vD/wNggnNuMoBzbodzrtA5VwS8AvT0MoNIWWKio3hoaAcevbQTs9bu4pIXZurDXhL2PCt+MzPgNWCFc+6p45Y3OO5ll1B8KUeRgLqyZxMm3NCL/UcKGPr8DB78aKn2/iVsVfpi6xV+4+K5faYDS4Bjg6f/B1xJ8TCPo/jiLjc758o8uqaLrYu/5Bw+ylNfr+KtOZuonRjH/7u4PcO66pwECU2lXWzds+KvSip+8belW3P4/YdLWbhlHyO6p/GnYR2oHl/RC9aJBIfSit8vZ/WIhJqOjWoxaXQf7jy7NZMXZHHxczNY9oPG/iU8qPhFShETHcXd57bhnRt6czC/gEtemMVbszfqE78S8lT8IuXo07IuX9w1kH6t6vKHj5Zx2zvz2X9EB34ldKn4RSqgTvU4XhvZg99e0Javlu1gyLMzdNqnhCwVv0gFRUUZo89syXs39+ZoYREjXpzFhwu2BjqWSKWp+EUq6Yymdfjkjv50aZzMmH8u1HQPEnJU/CInISUpngk39PrvdA/XvDZXF3aXkKHiFzlJsb7pHv56eRcyN+/l4udmsDhrX6BjiZRLxS9yii47I40PRvfFzLjspdm8N2+LTvmUoKbiF6kCndJq8ckd/enRrDb3fbCY299dwL5D+YGOJVIiFb9IFalTPY43r+/FveedzldLt/Ozp6fp4u4SlFT8IlUoOsq47axWfHhbP2olxHLtG/N4+NPlHNVZPxJEVPwiHujYqHjo51d9mvLqjA1c/er3ZB/QWT8SHFT8Ih6pFhvNn4Z15OlfdGFR1j6GPDedjI17Ah1LRMUv4rVLuqUx+ZZ+xMdEc/nLs3nwo6Uc0Fw/EkAqfhE/aN+wJp/d2Z+RfZrx5pxNnPPUd3yxpMzrD4l4RsUv4ic1qsXy0NAOfHhrP1KS4rllwnwe/WIFRUU651/8S8Uv4mddGifz0W39uLp3E17+bj13/XMheQWFgY4lEUTXkhMJgJjoKP48rCONkhN5/MuV7Nx/hLHXpFMrMTbQ0SQCaI9fJEDMjFsGteTvV3Rl/ua9XP7yLLbnHAl0LIkAKn6RABvWtRHjr+vJD/uOMOLFWazdmRvoSBLmPCt+M2tsZlPMbLmZLTOzu3zL65jZN2a2xvdnba8yiISKvq1SmHhTb/IKCrn8pVks2Lw30JEkjHm5x18A3OOcaw/0Bm4zs/bAb4FvnXOtgW99j0UiXsdGtZg0ui81qsXyi7FzeHfuZs3yKZ7wrPidc9ucc/N99w8AK4BGwDBgvO9l44HhXmUQCTXNUqrzr1v70qt5HR6YvIR73lvEofyCQMeSMOOXMX4zawZ0A74H6jvnjn1yZTtQv5R1bjKzDDPLyM7O9kdMkaBQNymecdf1ZMw5rfnXwq0Mf2EmG3YdDHQsCSOeF7+ZJQEfAGOcc/uPf84V/x5b4u+yzrmxzrl051x6amqq1zFFgkp0lDHmnDa8eX1Psg/kMez5GZriWaqMp8VvZrEUl/4E59xk3+IdZtbA93wDQN/NIqUY0DqVj2/vT8PkBK4fN4+Xv1uncX85ZV6e1WPAa8AK59xTxz31MTDSd38k8JFXGUTCQeM6iUy+tS8XdGzAo1+s5MY3M9m5X+f7y8nzco+/H3ANMNjMFvpuFwKPAeea2RrgHN9jESlDYlwMz/+yG7+/qB3T12Rz7tPT+NeCLO39y0mxUPjGSU9PdxkZGYGOIRIU1mXnct+kxWRu2su57evz5GWdSU6MC3QsCUJmlumcSz9xuT65KxJiWqYm8d7Nffj9Re2YumonFz07g4Vb9gU6loQQFb9ICIqOMm4Y0IJJo/sCcPlLsxg3c4OGfsLIkaOFZGzcw+H8qp+5VcUvEsK6NE7mszv7M7B1Kg99spzb31mgq3uFiaVbc7jspdnMWLuryt9bxS8S4pIT43jlV+n89oK2fLlsO8Oen8nK7fvLX1GC2pKtOQB0alSryt9bxS8SBqKijNFntuSdG3qRm1fA8Bdm8vacTRr6CWFLtuaQkhRP/ZrxVf7eKn6RMNKrRV0+u3MAPZrV4fcfLuWqV79n8+5DgY4lJ2HZ1v10alST4o9EVS0Vv0iYSa0Rz5vX9+TRSzuxOCuH856ZxvhZG3Vt3xByOL+QNTsP0NGDYR5Q8YuEJTPjyp5N+PrXA+nZvA4PfryMa8fN0yd+Q8Tybfspcqj4RaTyGiYnMO66Hjw8vCNzN+zmvGem8dWy7YGOJeVY6uGBXVDxi4Q9M+Pq3k359I4BNKqdwM1vZXL7O/PZob3/oLVkaw51q8fRoFY1T95fxS8SIVrVS2LyLf24+9w2fL18B+f87TvGz9pIocb+g87SrTl0bFTLkwO7oOIXiShxMVHceXZrvh4zkK5Nknnw42VcMXY223O09x8sjhwtZM3OXM+GeUDFLxKRmqVU583re/K3y7uw7If9XPjsdKat1pXugsHybfspLHKeHdgFFb9IxDIzRpyRxse39yclKY6Rb8zlqa9XaegnwP57YDdNxS8iHmlVL4mPbuvPZd3TePY/a/nlK3M09BNAS7JyqFM9joYeHdgFFb+IAAlx0Tx5eRee+nkXlmzN4cJnpzNlpa6KGghLPD6wCyp+ETnOpd3T+OSO/tSrEc914+Zx/6TF7D2YH+hYEePHA7s1Pd2Oil9E/kfL1CQ+vK0fNw9swaT5WZz91HdMytRlHv1hhe/Arpdn9ICKX0RKUC02mgcubMdnd/aneUp1fvP+In71+lxN+eCxYwd2vTyjB1T8IlKGtqfV5P2b+/Dn4R2Zt3EP5/99Ov9eviPQscLWsh/2k5wYS6PkBE+3o+IXkTJFRRnX+KZ8OK1mNW54M4Pff7iEQ/kFgY4WdlZuP0Db02p4emAXPCx+M3vdzHaa2dLjlj1kZlvNbKHvdqFX2xeRqtWqXhL/uq0vNw5ozttzNnPB36eTsXFPoGOFjaIix+odB2h7mrcHdsHbPf5xwPklLH/aOdfVd/vcw+2LSBWLj4nmdxe1Z+JNvSlyjstfns1fPl/BwTzt/Z+qLXsPcSi/kLan1fB8W54Vv3NuGqDdAZEw1LtFXb64ayBX9mzC2GnrGfjEFMZOW8fh/MJARwtZK7cfAOD0UC7+MtxuZot9Q0G1S3uRmd1kZhlmlpGdrTlERIJNUnwMf7mkE5Nv7Uv7hjX5y+crGfDEFF6fsYG8Av0AqKyV2w5gBm3qh1/xvwi0BLoC24C/lfZC59xY51y6cy49NTXVT/FEpLK6N6nNW6N68f7oPrSul8SfPl3O4L9+x/sZWzTvTyWs2rGfJnUSqR4f4/m2/Fr8zrkdzrlC51wR8ArQ05/bFxHv9GhWh3dv6s3bo3pRp3oc905azHnPTOPzJdt0vd8KWLn9AKf7YW8f/Fz8ZtbguIeXAEtLe62IhKb+rVP4+PZ+vPDL7jjnuHXCfC5+fgZTVu7Up39LceRoIRt3HaRtA+/P6AHw7HcKM3sXGASkmFkW8CAwyMy6Ag7YCNzs1fZFJHDMjIs6N+C8DvX5aOEPPPPtaq4bN4+ezevwwAVt6dak1MN7EWnNjlyKHH45owc8LH7n3JUlLH7Nq+2JSPCJiY5ixBlpDO3akInztvD3f6/mkn/M4qJODbj3vNNpllI90BGDwsrt+wH/nNEDHha/iMgxsdFRXNO7KZd0a8Qr09bzyvT1fLVsOz/v0Zi7zm5N/ZrezT0fClZuP0B8TBTN6vrnB6GmbBARv0mKj+HX57Zh6r2DuKpXE97P2MKZT07h0c9XsCeCp39etf0AberXIDrK26kajlHxi4jf1atRjT8O68h/7hnEhR0bMHb6evo//h8e/3JlRP4AWLn9gN+GeUDFLyIB1LhOIk/9oivf/Hog57Srz0vfrWPA4//h0c9XsPNAZEwBvSs3j125eX47sAsqfhEJAq3q1eDZK7vx9ZiBnN2uPq9MX0//x6fwhw+XsnXf4UDH89Qq31QN/pic7RgVv4gEjdb1i38AfHvPIC7t1oiJ8zZz1pNT+cvnK8g5dDTQ8Tzhzzl6jlHxi0jQaZ5SncdGdGbqvWcxtGtDXpm+noFPTuGFKWtZkpXD0cKiQEesMqu27yclKY7UGvF+26ZO5xSRoNUoOYG/Xt6FUf2b89gXK3nyq1U8+dUqEmKj6dK4Fj9Pb8ywro38djaMF1Zs8++BXVDxi0gIaNegJuOv78nWfYfJ3LSX+Zv2MmPtLu5+bxHPT1nLmHPacFGnBiH3A+Cf8zazZGsO95zbxq/btVCYOyM9Pd1lZGQEOoaIBJGiIsfXy7fz9DdrWLXjAM1TqnNN76aMOCONWgmxgY5Xrmmrs7lu3Dz6tUrhtZHpxEZX/ci7mWU659J/slzFLyKhrKjI8cXS7bw2Yz3zN+8jITaa4d0acXl6Gt0aJ3t+/dqTsXL7fi57cTZptRN4f3QfalTz5geVil9Ewt7SrTm8OXsjHy38gbyCIlqkVOfS7o34eXpj6gXJtBBzN+zhrokLKHKOD2/rR4NaCZ5tS8UvIhHjwJGjfLFkOx/Mz+L7DXuIi45ixBmNuHFAC1qkJgUk05KsHJ78ehXTVmdTv2Y8r1/bgw4Na3m6TRW/iESkDbsO8ur09byfmcXRwiLObJPKz9qfxtnt6vltcri/frWK56esJTkxllsHteSa3s1IiIv2fLsqfhGJaNkH8hg/ayMfLtxK1t7iTwN3SavFeR1P4/wOp3n2m8Dk+Vnc/d4iRnRP46Gh7T0bzy+Jil9EBHDOsXpHLv9esYOvl21nUVYOAG3qJzHo9Hr0aVGXHs3rkFQF175dnLWPy16aTfcmybw1qpcnZ+6URcUvIlKCrfsO8/Wy7Xy1bDvzN+0jv7CI6Cijc1otBrZOZWCbVLo2Tq70ZwR2HjjC0OdmEh1lfHJHf+pUj/PoKyidil9EpBxHjhaSuWkvs9ftZsbaXSzK2odzkBgXTe3EOKrHR5MUH0P7hjU5s009+rSs+5PfDHIOHeWLpdt4feYGtuw5zKRb+nh+ELc0Kn4RkUraezCfGWt3MX/zXvYfLuBgXgE5h4+yKGsfh/ILiY02WterQc2EGJLiY8kvLGL2ul0cLXQ0q5vIH4a05+x29QOWX8UvIlJF8guKyNi0h+9WZ7NmRy65Rwo4kFdAYVERA1unMrRrQzo1qhXwD4+VVvyaq0dEpJLiYqLo2zKFvi1TAh3lpHh2iNnMXjeznWa29LhldczsGzNb4/uztlfbFxGRknl5btE44PwTlv0W+NY51xr41vdYRET8yLPid85NA/acsHgYMN53fzww3Kvti4hIyfx9Ba76zrltvvvbgVIPd5vZTWaWYWYZ2dnZ/kknIhIBAnbpRVd8OlGppxQ558Y659Kdc+mpqal+TCYiEt78Xfw7zKwBgO/PnX7evohIxPN38X8MjPTdHwl85Ofti4hEPC9P53wXmA2cbmZZZjYKeAw418zWAOf4HouIiB+FxCd3zSwb2OR7WAvIKeP+iX+mALsqucnj37ciz524rKzHoZCzrLyVzVlWxpPJWdF//2DMGYh/81DJqf9DJ5exvJxNnXM/PUjqnAupGzC2rPsl/JlxKtuoyHMnLivrcSjkLCdvpXKWlfFkclbi3z/ocgbi3zxUcur/kLffmyfeAnZWzyn4pJz7J/55qtuoyHMnLivrcSjkLCtvZZW3XmVzVvTfv7L8kTMQ/+YlLQ/GnPo/VLkc5T1f5johMdRzKswsw5UwSVGwUc6qFQo5QyEjKGdVC4acobjHX1ljAx2ggpSzaoVCzlDICMpZ1QKeM+z3+EVE5H9Fwh6/iIgcR8UvIhJhVPwiIhFGxS8iEmEiuvjNbICZvWRmr5rZrEDnKY2ZRZnZI2b2nJmNDHSe0pjZIDOb7vs7HRToPKUxs+q+Kb+HBDpLacysne/vcZKZ3RLoPKUxs+Fm9oqZ/dPMfhboPKUxsxZm9pqZTQp0luP5vhfH+/4Or/LXdkO2+Eu6tKNv+flmtsrM1ppZmVf4cs5Nd86NBj7lxwvEBF1Oii9gkwYcBbKCOKcDcoFqXuSsoowA9wPvVXW+4/JUxffmCt/35s+BfkGc80Pn3I3AaOAXQZxzvXNulBf5TlTJvJcCk3x/h0P9kQ8IvSkbjvtI8kCgO7D0uGXRwDqgBRAHLALaA50oLvfjb/WOW+89oEaw5qT4EpU3+9adFMQ5o3zr1QcmBGnGc4ErgGuBIcH6d+lbZyjwBfDLYM7pW+9vQPcQyOnJ/59TyPsA0NX3mne8znbsFkOIcs5NM7NmJyzuCax1zq0HMLOJwDDn3KNAib/Wm1kTIMc5dyBYc5pZFpDve1gYrDmPsxeID8aMviGo6hT/pztsZp8754qCLafvfT4GPjazz4B3qjJjVeU0M6N4lt0vnHPzqzpjVeX0p8rkpfg34zRgIX4cgQnZ4i9FI2DLcY+zgF7lrDMKeMOzRCWrbM7JwHNmNgCY5mWwE1Qqp5ldCpwHJAPPe5rsR5XK6Jz7HYCZXQvsqurSL0Nl/y4HUTwMEA987mWwE1T2e/MOiqdYr2VmrZxzL3kZ7jiV/fusCzwCdDOzB3w/IPyptLzPAs+b2UWc2pxDlRJuxV9pzrkHA52hPM65QxT/gApqzrnJFP+QCnrOuXGBzlAW59xUYGqAY5TLOfcsxeUV1Jxzuyk+DhFUnHMHgev8vd2QPbhbiq1A4+Mep/mWBRvlrDqhkBGUs6qFSs5jgipvuBX/PKC1mTU3sziKD+J9HOBMJVHOqhMKGUE5q1qo5DwmuPL66yiyB0fO3wW28eMpjqN8yy8EVlN8BP13yhk+OUMho3JGbs5QyqvZOUVEIky4DfWIiEg5VPwiIhFGxS8iEmFU/CIiEUbFLyISYVT8IiIRRsUvIcvMcv28vSq5ZoMVX7cgx8wWmtlKM/trBdYZbmbtq2L7Iip+ER8zK3PuKudc3yrc3HTnXFegGzDEzMqbc384xTOKipwyFb+EFTNraWZfmlmmFV8NrK1v+cVm9r2ZLTCzf5tZfd/yh8zsLTObCbzle/y6mU01s/Vmdudx753r+3OQ7/lJvj32Cb7piTGzC33LMs3sWTP7tKy8zrnDFE/J28i3/o1mNs/MFpnZB2aWaGZ9KZ6b/0nfbwktS/s6RSpCxS/hZixwh3PuDOA3wD98y2cAvZ1z3YCJwH3HrdMeOMc5d6XvcVuKp5fuCTxoZrElbKcbMMa3bgugn5lVA14GLvBtP7W8sGZWG2jNj9NtT3bO9XDOdQFWUPxx/1kUz+tyr3Ouq3NuXRlfp0i5In5aZgkfZpYE9AXe9+2Aw48XhEkD/mlmDSi+AtKG41b92Lfnfcxnzrk8IM/MdlJ8RbETLyU51zmX5dvuQqAZxZedXO+cO/be7wI3lRJ3gJktorj0n3HObfct72hmD1N8TYMk4KtKfp0i5VLxSziJAvb5xs5P9BzwlHPuY99FTh467rmDJ7w277j7hZT8/6QirynLdOfcEDNrDswxs/eccwuBccBw59wi38ViBpWwbllfp0i5NNQjYcM5tx/YYGaXQ/FlAc2si+/pWvw4//lIjyKsAlocd9m9ci8+7vvt4DGKLwAPUAPY5hteuuq4lx7wPVfe1ylSLhW/hLJEM8s67nY3xWU5yjeMsozi65pC8R7++2aWCezyIoxvuOhW4Evfdg4AORVY9SVgoO8Hxh+A74GZwMrjXjMRuNd3cLolpX+dIuXStMwiVcjMkpxzub6zfF4A1jjnng50LpHjaY9fpGrd6DvYu4zi4aWXAxtH5Ke0xy8iEmG0xy8iEmFU/CIiEUbFLyISYVT8IiIRRsUvIhJh/j/0U0L+nzL0jAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr = 0.005120108485221863 #0.33113112449646 #0.06309573650360108 #0.0015848932266235352 #0.13182567358016967#0.03019951581954956#0.002290867641568184#0.19054607152938843"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.load(\"bestmodel_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/300 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='30' class='' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      10.42% [30/288 01:30<12:54 10.1535]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(learn.model.state_dict(), \"./Model_saves/torch-best-1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.save(\"cnn_model_best_1_80\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = pl.callbacks.ModelCheckpoint(dirpath=\"Model_saves/\", monitor=\"val_loss\", mode=\"min\", verbose=True, filename=\"lightnng_save_lstm.pt\")\n",
    "\n",
    "# trainer = pl.Trainer(gpus=[0],max_epochs=20, \\\n",
    "#                     precision=16, \\\n",
    "#                     amp_backend=\"native\",\\\n",
    "#                     num_sanity_val_steps=10, \\\n",
    "#                     benchmark=True, reload_dataloaders_every_epoch=True, \\\n",
    "#                     weights_save_path=\"./Model_saves/\", weights_summary=\"top\", \\\n",
    "#                     profiler=\"simple\",  callbacks=[checkpoint])\n",
    "\n",
    "\n",
    "# lr_finder = trainer.tuner.lr_find(model, dls.train, dls.valid)\n",
    "\n",
    "# fig = lr_finder.plot(suggest=True); fig.show()\n",
    "\n",
    "# lr_finder.suggestion()\n",
    "\n",
    "# trainer.fit(model, dls.train, dls.valid)x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(\"bestmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = learn.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake_inputs = torch.randn(BATCH_SIZE, int(default_sr*sec)).type(torch.float32).to(device)\n",
    "# outs = model(fake_inputs)\n",
    "# outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"./Model_saves/Pytorch_model_2_save_LSTM_512_filters.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    \n",
    "    loop = tqdm(enumerate(data_loader), leave=True, total=len(data_loader))\n",
    "    train_loss = np.zeros((len(data_loader)))\n",
    "    loop.set_description(f\"Epoch: [ {epoch}/{n_epochs} ]\\t\")\n",
    "\n",
    "    \n",
    "    for index, (data, target) in loop:\n",
    "        \n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        for group in optimizer.param_groups:\n",
    "            for param in group[\"params\"]:\n",
    "                param.data = param.data.add(-w_decay * group[\"lr\"], param.data)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "#         output = model(data)\n",
    "#         loss = criterion(output, target)\n",
    "        \n",
    "#         loss.backward()\n",
    "#         for group in optimizer.param_groups:\n",
    "#             for param in group[\"params\"]:\n",
    "#                 param.data = param.data.add(-w_decay * group[\"lr\"], param.data)\n",
    "#         optimizer.step()\n",
    "\n",
    "        train_loss[index] = loss.item()\n",
    "        if np.isnan(loss.item()) or np.isnan(np.sum(train_loss)/index+1e-5):\n",
    "            print(f\"Data shape = {data.shape}\\nTarget Shape = {target.shape}, \\nindex = {index}\")\n",
    "        disp_loss = np.sum(train_loss)/index+1e-5\n",
    "        loop.set_postfix(loss = disp_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(learn.model.state_dict(), \"./Model_saves/torch_model_save_latge_dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.load_state_dict(torch.load(\"./Model_saves/torch-best-1.pt\"))\n",
    "device = \"cpu\"\n",
    "model.to(device)\n",
    "# torch.save(model.state_dict(), \"./Model_saves/torch_model_save_latge_dataset_cpu.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "noise_add_sig, main_sig = val_ds.__getitem__(346)\n",
    "noise_add_sig = torch.unsqueeze(noise_add_sig, dim=0).to(device)\n",
    "main_sig = torch.unsqueeze(main_sig, dim=0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outs = model(noise_add_sig).squeeze()\n",
    "\n",
    "outs.shape\n",
    "\n",
    "x = outs.t().to(\"cpu\").numpy()\n",
    "ipd.Audio(x, rate=default_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs.squeeze().t().to(\"cpu\").numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = noise_add_sig.squeeze().t().to(\"cpu\").numpy()\n",
    "ipd.Audio(x, rate=default_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = main_sig.squeeze().t().to(\"cpu\").numpy()\n",
    "ipd.Audio(x, rate=default_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_add_sig.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(10, 10))\n",
    "axes[0].plot(main_sig.squeeze().t().to(device).numpy())\n",
    "axes[1].plot(noise_add_sig.squeeze().t().to(device).numpy())\n",
    "axes[2].plot(outs.t().squeeze().to(device).numpy())\n",
    "\n",
    "axes[0].title.set_text(\"Main Signal\")\n",
    "axes[1].title.set_text(\"Noised speech Signal\")\n",
    "axes[2].title.set_text(\"Predicted Signal\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"Audio_Signals_Plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
