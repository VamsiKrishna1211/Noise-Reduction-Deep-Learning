{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio as ta\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd.profiler as profiler\n",
    "\n",
    "# import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "import glob\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from python_files.Noise_Reduction_Datagen import Signal_Synthesis_DataGen\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import gc\n",
    "\n",
    "# from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noise from saved file\n",
      "Loading nums from npy file\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "noise_dir = \"./dataset/UrbanSound8K-Resampled/audio/\"\n",
    "signal_dir = \"./dataset/cv-corpus-5.1-2020-06-22-Resampled/en/clips/\"\n",
    "signal_nums_save = \"./dataset_loader_files/signal_paths_nums_save.npy\"\n",
    "num_noise_samples=100\n",
    "num_signal_samples = 100\n",
    "noise_save_path = \"./dataset_loader_files/noise_paths_resampled_save.npy\"\n",
    "n_fft=512\n",
    "win_length=n_fft\n",
    "hop_len=n_fft//4\n",
    "create_specgram = False\n",
    "perform_stft = False\n",
    "default_sr = 16000\n",
    "sec = 9\n",
    "augment=True\n",
    "device_datagen = \"cpu\"\n",
    "\n",
    "signal_synthesis_dataset = Signal_Synthesis_DataGen(noise_dir, signal_dir, \\\n",
    "                signal_nums_save=signal_nums_save, num_noise_samples=num_noise_samples, \\\n",
    "                num_signal_samples=num_signal_samples, noise_path_save=noise_save_path, \\\n",
    "                 n_fft=n_fft, win_length=win_length, hop_len=hop_len, create_specgram=create_specgram, \\\n",
    "                 perform_stft=perform_stft, normalize=True, default_sr=default_sr, sec=sec, epsilon=1e-5, augment=False, device=device_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BATCH_SIZE = 3\n",
    "shuffle = True\n",
    "num_workers = 8\n",
    "pin_memory = False\n",
    "# data_loader = DataLoader(signal_synthesis_dataset, batch_size=BATCH_SIZE, shuffle=shuffle, num_workers=num_workers)\n",
    "data_loader = DataLoader(signal_synthesis_dataset, batch_size=BATCH_SIZE, shuffle=shuffle, num_workers=num_workers, pin_memory=pin_memory)\n",
    "# data_loader.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_synthesis_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # data_loader_iter = iter(data_loader)\n",
    "# for index, i in enumerate(data_loader):\n",
    "# #     i = next(data_loader)\n",
    "#     if index < 32-1:\n",
    "#         pass\n",
    "#     else:\n",
    "#         break\n",
    "#     print(i[1].shape,i[0].min(), i[0].max(), index)\n",
    "\n",
    "# %%time\n",
    "# stft_sig = torch.stft(i[0], n_fft=n_fft, hop_length=hop_len, win_length=win_length)\n",
    "\n",
    "# i[1].max()\n",
    "\n",
    "# nan_sig = signal_synthesis_dataset.__getitem__(119)\n",
    "\n",
    "# nan_sig[0].max(), nan_sig[1].min()\n",
    "\n",
    "# stft_sig.max()\n",
    "\n",
    "# def normalize(tensor):\n",
    "#     tensor_minusmean = tensor - tensor.min()\n",
    "#     return tensor_minusmean/tensor_minusmean.abs().max()\n",
    "\n",
    "# aud = i[0][0]\n",
    "\n",
    "# aud.dtype\n",
    "\n",
    "# aud.max(), aud.min()\n",
    "\n",
    "# x = aud.t().to(\"cpu\").numpy()\n",
    "# ipd.Audio(x, rate=default_sr)\n",
    "\n",
    "# sig1 = i[0].unsqueeze(dim=1)\n",
    "# sig2 = i[0].unsqueeze(dim=1)\n",
    "# stacked_sig = torch.cat((sig1, sig2), dim=1)\n",
    "\n",
    "# sig2 = i[0].unsqueeze(dim=1)\n",
    "# sig2.shape\n",
    "\n",
    "# torch.sum(stacked_sig, dim=1).shape\n",
    "\n",
    "# np.floor(((default_sr*sec) - (win_length - 1) - 1)/ hop_len + 5)\n",
    "\n",
    "# n_fft // 2 + 1\n",
    "\n",
    "# n_fft // 2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstantLayerNormalization(nn.Module):\n",
    "    def __init__(self, in_shape, out_shape):\n",
    "        self.in_shape = in_shape\n",
    "        self.out_shape = out_shape\n",
    "        \n",
    "        self.epsilon = 1e-7\n",
    "        self.gamma = None\n",
    "        self.beta = None\n",
    "        \n",
    "        super(InstantLayerNormalization, self).__init__()\n",
    "        \n",
    "        self.gamma = torch.ones(out_shape)\n",
    "        self.gamma = nn.Parameter(self.gamma)\n",
    "        \n",
    "        self.beta = torch.zeros(out_shape)\n",
    "        self.beta = nn.Parameter(self.beta)\n",
    "        \n",
    "    def forward(self, inps):\n",
    "        mean = inps.mean(-1, keepdim=True)\n",
    "        variance = torch.mean(torch.square(inps - mean), dim=-1, keepdim=True)\n",
    "        std = torch.sqrt(variance + self.epsilon)\n",
    "        \n",
    "        outs = (inps - mean) / std\n",
    "        print(outs.shape, self.gamma.shape)\n",
    "        outs = outs * self.gamma\n",
    "        outs = outs + self.beta\n",
    "        \n",
    "        return outs\n",
    "    \n",
    "class Multiply():\n",
    "    def __init__(self):\n",
    "        super(Multiply, self).__init__()\n",
    "    \n",
    "    def forward(self, ten1, ten2):\n",
    "        mul_out = torch.mul(ten1, ten2)\n",
    "        return mul_out\n",
    "\n",
    "class NoiseReducer(nn.Module):\n",
    "    def __init__(self, default_sr, n_fft, win_length, hop_len, sec, dropout=0.5, batch_first=True, stride=2, normalized=False, bidir=False):\n",
    "        \n",
    "        self.default_sr = default_sr\n",
    "        self.n_fft = n_fft\n",
    "        self.win_length = win_length\n",
    "        self.hop_len = hop_len\n",
    "        self.sec = sec\n",
    "        self.normalized = normalized\n",
    "        \n",
    "        self.conv_filters = 256\n",
    "        \n",
    "        # Universal LSTM Units\n",
    "        self.batch_first = True\n",
    "        self.dropout = 0.25\n",
    "        self.bidir = bidir\n",
    "        \n",
    "        # LSTM 1 UNITS\n",
    "        self.rnn1_dims = n_fft // 2 + 1\n",
    "        self.hidden_size_1 = 128\n",
    "        self.num_layers = 2\n",
    "       \n",
    "        \n",
    "        # LSTM 2 UNITS\n",
    "        self.rnn2_dims = self.conv_filters\n",
    "        self.hidden_size_2 = self.hidden_size_1\n",
    "        \n",
    "        # Conv1d Layer Units\n",
    "        self.conv1_in = 1\n",
    "        self.conv1_out = self.conv_filters\n",
    "        \n",
    "        \n",
    "        \n",
    "        # InstanceNorm Layer Units\n",
    "        self.instance1_in = self.rnn1_dims\n",
    "        self.instance2_in = self.conv1_out\n",
    "        \n",
    "        # Dense1 Layer Units\n",
    "        self.dense1_in = self.hidden_size_2\n",
    "        self.dense1_out = self.rnn1_dims #int(np.floor(((default_sr*sec) - (win_length - 1) - 1)/ hop_len + 5))#3))\n",
    "        \n",
    "        # Dense2 Layer Units\n",
    "        self.dense2_in = self.hidden_size_2\n",
    "        self.dense2_out = self.conv1_out\n",
    "        \n",
    "        # Conv2d Layer Units\n",
    "        self.conv2_in = self.dense2_out\n",
    "        self.conv2_out = self.conv_filters\n",
    "        \n",
    "\n",
    "        super(NoiseReducer, self).__init__()\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size=self.rnn1_dims, hidden_size=self.hidden_size_1, num_layers=self.num_layers, batch_first=self.batch_first, dropout=self.dropout, bidirectional=self.bidir)\n",
    "        \n",
    "        print(self.rnn2_dims)\n",
    "        self.lstm2 = nn.LSTM(input_size=self.rnn2_dims, hidden_size=self.hidden_size_2, num_layers=self.num_layers, batch_first=self.batch_first, dropout=self.dropout, bidirectional=self.bidir)\n",
    "        \n",
    "        \n",
    "        self.instancenorm1 = nn.InstanceNorm1d(self.rnn1_dims)\n",
    "        self.instancenorm2 = nn.InstanceNorm1d(self.rnn2_dims)\n",
    "        \n",
    "        self.dense1 = nn.Linear(self.dense1_in, self.dense1_out)\n",
    "        self.dense2 = nn.Linear(self.dense2_in, self.dense2_out)\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(self.conv1_in, self.conv1_out, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(self.conv2_in, self.conv2_out, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "    @torch.jit.export\n",
    "    def stft_layer(self, sig):\n",
    "        \n",
    "        sig_stft = torch.stft(sig, n_fft=self.n_fft, hop_length=self.hop_len, win_length=self.win_length)\n",
    "        \n",
    "        sig_cplx = torch.view_as_complex(sig_stft)\n",
    "        mag = sig_cplx.abs().permute(0, 2, 1)\n",
    "        angle = sig_cplx.angle().permute(0, 2, 1)\n",
    "        \n",
    "        return [mag, angle]\n",
    "    \n",
    "    @torch.jit.export\n",
    "    def istft_layer(self, mag, angle):\n",
    "        mag = mag.permute(0, 2, 1)\n",
    "        angle = angle.permute(0, 2, 1)\n",
    "        mag = torch.unsqueeze(mag, dim=-1)\n",
    "        angle = torch.unsqueeze(angle, dim=-1)\n",
    "        pre_stft = torch.cat((mag, angle), dim=-1)\n",
    "        stft_sig = torch.istft(pre_stft, n_fft=self.n_fft, win_length=self.win_length, hop_length=self.hop_len)\n",
    "        \n",
    "        return stft_sig\n",
    "    \n",
    "    \n",
    "    def forward(self, inp_tensor):\n",
    "        \n",
    "        mag, angle = self.stft_layer(inp_tensor)\n",
    "        mag_norm = self.instancenorm1(mag)\n",
    "        x, hidden_states = self.lstm1(mag_norm)\n",
    "\n",
    "        mask = self.dense1(x)\n",
    "        estimated_mag = torch.mul(mag, mask)\n",
    "        \n",
    "        signal = self.istft_layer(estimated_mag, angle)\n",
    "        signal = signal.unsqueeze(dim=1)\n",
    "\n",
    "        feature_rep = self.conv1(signal)\n",
    "        \n",
    "        feature_norm = self.instancenorm2(feature_rep)\n",
    "        feature_norm = feature_norm.permute(0, 2, 1)\n",
    "        x, hidden_states = self.lstm2(feature_norm)\n",
    "        mask = self.dense2(x)\n",
    "        feature_mask = F.sigmoid(mask)\n",
    "        feature_mask = feature_mask.permute(0, 2, 1)\n",
    "\n",
    "        estimate_feat = torch.mul(feature_rep, feature_mask)\n",
    "        \n",
    "        estimate_frames = self.conv2(estimate_feat)\n",
    "        estimate_sig = torch.sum(estimate_frames, dim=1)\n",
    "        \n",
    "        return estimate_sig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "scripted_model = torch.jit.script(NoiseReducer(default_sr, n_fft, win_length, hop_len, sec).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scripted_model.code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Negative_SNR_Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Negative_SNR_Loss, self).__init__()\n",
    "    \n",
    "    def forward(self, sig_pred, sig_true):\n",
    "        \n",
    "        sig_true_sq = torch.square(sig_true)\n",
    "        sig_pred_sq = torch.square(sig_true - sig_pred)\n",
    "\n",
    "        sig_true_mean = torch.mean(sig_true_sq)\n",
    "        sig_pred_mean = torch.mean(sig_pred_sq)\n",
    "\n",
    "        snr = sig_true_mean / sig_pred_mean + 1e-7\n",
    "        loss = -1*torch.log10(snr)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Scripted Model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "use_scripted_model = True\n",
    "\n",
    "if not use_scripted_model:\n",
    "    print(\"Using Primary model\")\n",
    "    model = NoiseReducer(default_sr=default_sr, n_fft=n_fft, win_length=win_length, hop_len=hop_len, sec=sec).to(device)\n",
    "    model.to(device)\n",
    "else:\n",
    "    print(\"Using Scripted Model\")\n",
    "    model = scripted_model\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = Negative_SNR_Loss()\n",
    "n_epochs=100\n",
    "\n",
    "model.train()\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outs = model(fake_inputs)\n",
    "# outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model, fake_inputs\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake_inputs = torch.randn(BATCH_SIZE, int(default_sr*sec)).to(device)\n",
    "# with profiler.profile(profile_memory=True, record_shapes=False, use_cuda=True) as prof:\n",
    "#     scripted_model(fake_inputs)\n",
    "# #     model(fake_inputs)\n",
    "# print(prof.key_averages().table(sort_by=\"cuda_time_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(\"Pytorch_model_save_scripted.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d0b8fa03e9437ab4d0a621c88ddd9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3334.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f79f28e60057>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyTorch-10.2/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyTorch-10.2/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs+1):\n",
    "    \n",
    "    loop = tqdm(enumerate(data_loader), leave=True, total=len(data_loader))\n",
    "    train_loss = np.zeros((len(data_loader)))\n",
    "    \n",
    "    for index, (data, target) in loop:\n",
    "        \n",
    "        data = data.type(torch.float32).to(device)\n",
    "        target = target.type(torch.float32).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss[index] = loss.item()\n",
    "        if np.isnan(loss.item()) or np.isnan(np.sum(train_loss)/index+1e-5):\n",
    "            print(f\"Data shape = {data.shape}\\nTarget Shape = {target.shape}, \\nindex = {index}\")\n",
    "        loop.set_description(f\"Epoch: [{epoch}/{n_epochs}]\\t\")\n",
    "        loop.set_postfix(loss = np.sum(train_loss)/index+1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(scripted_model.state_dict(), \"./Pytorch_model_save_scripted.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_add_sig, main_sig = signal_synthesis_dataset.__getitem__(1000)\n",
    "noise_add_sig = torch.unsqueeze(noise_add_sig, dim=0).to(device)\n",
    "main_sig = torch.unsqueeze(main_sig, dim=0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    outs = model(noise_add_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = outs[0].t().to(\"cpu\").numpy()\n",
    "ipd.Audio(x, rate=default_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = noise_add_sig[0].t().to(\"cpu\").numpy()\n",
    "ipd.Audio(x, rate=default_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = main_sig[0].t().to(\"cpu\").numpy()\n",
    "ipd.Audio(x, rate=default_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
