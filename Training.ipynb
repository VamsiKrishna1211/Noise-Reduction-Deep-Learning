{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio as ta\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import pytorch_lightning as pl\n",
    "\n",
    "import os\n",
    "\n",
    "import librosa\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import glob\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from Noise_Reduction_Datagen import Signal_Synthesis_DataGen\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import gc\n",
    "\n",
    "# from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dir = \"./dataset/UrbanSound8K/audio/\"\n",
    "noise_metadata = \"./dataset/UrbanSound8K/metadata/UrbanSound8K.csv\"\n",
    "signal_dir = \"./dataset/cv-corpus-5.1-2020-06-22/en/clips/\"\n",
    "signal_metadata = \"./dataset/cv-corpus-5.1-2020-06-22/en/train.tsv\"\n",
    "num_samples = 300\n",
    "signal_save_path = \"./dataset_loader_files/signal_paths_save.npy\"\n",
    "noise_save_path = \"./dataset_loader_files/noise_paths_save.npy\"\n",
    "default_sr = 16000\n",
    "sec = 6\n",
    "augment=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from npy file\n"
     ]
    }
   ],
   "source": [
    "signal_synthesis_dataset = Signal_Synthesis_DataGen(\n",
    "                                noise_dir=noise_dir,\n",
    "                                noise_metadata=noise_metadata,\n",
    "                                signal_dir=signal_dir,\n",
    "                                signal_metadata=signal_metadata,\n",
    "                                num_samples=num_samples,\n",
    "                                signal_path_save=signal_save_path,\n",
    "                                noise_path_save=noise_save_path,\n",
    "                                default_sr=default_sr,\n",
    "                                sec=sec,\n",
    "                                augment=augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "shuffle = False\n",
    "num_workers = 1\n",
    "data_loader = DataLoader(signal_synthesis_dataset, batch_size=BATCH_SIZE, shuffle=shuffle, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model building\n",
    "# class BiDirectLSTM(nn.Module):\n",
    "#     def __init__(self, rnn_dim, hidden_size, dropout, batch_first=True):\n",
    "#         super(BiLSTM, self).__init__()\n",
    "        \n",
    "#         self.BiLSTM = nn.LSTM(\n",
    "#                 input_size=rnn_dim,\n",
    "#                 hidden_size=hidden_size,\n",
    "#                 num_layers=2, batch_first=batch_first, bidirectional=True)\n",
    "#         self.layer_norm = nn.LayerNorm(rnn_dim)\n",
    "#         self.dropout(dropout)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.layer_norm(x)\n",
    "#         x = F.gelu(x)\n",
    "#         x, _ = self.BiLSTM(x)\n",
    "#         x = self.dropout(x)\n",
    "#         return x\n",
    "        \n",
    "\n",
    "\n",
    "# class NoiseReducer(nn.Module):\n",
    "#     super(NoiseReducer, self).__init__()\n",
    "#     def __init__(self, default_sr, n_fft, win_length, hop_len, f_min, f_max, rnn_dims, dropout=0.5, batch_first=True, stride=2, normalized=True):\n",
    "        \n",
    "#         self.n_fft = n_fft\n",
    "#         self.win_length = win_length\n",
    "#         self.hop_len = hop_len\n",
    "#         self.f_min = f_min\n",
    "#         self.f_max = f_max\n",
    "#         self.normalized = normalized\n",
    "        \n",
    "#         self.specgram = ta.transforms.Spectrogram(n_fft=n_fft, win_length=win_length, hop_length=hop_len)\n",
    "#         self.inv_spec = ta.transforms.GriffinLim(n_fft=n_fft, win_length=win_length, hop_length=hop_len, \n",
    "#                                                  rand_init=False, normalized=normalized, momentum=0.9)\n",
    "#         self.bilstm1 = BiDirectLSTM(rnn_dim=rnn_dim, hidden_size=rnn_dim, dropout=dropout, batch_first=batch_first)\n",
    "#         self.bilstm2 = BiDirectLSTM(rnn_dim=rnn_dim, hidden_size=rnn_dim, dropout=dropout, batch_first=batch_first)\n",
    "        \n",
    "#         self.conv1 = nn.Conv2d\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 >= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428218200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_synthesis_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 96000]) 0\n",
      "torch.Size([8, 96000]) 1\n",
      "torch.Size([8, 96000]) 2\n",
      "torch.Size([8, 96000]) 3\n",
      "torch.Size([8, 96000]) 4\n",
      "torch.Size([8, 96000]) 5\n",
      "torch.Size([8, 96000]) 6\n",
      "torch.Size([8, 96000]) 7\n",
      "torch.Size([8, 96000]) 8\n",
      "torch.Size([8, 96000]) 9\n",
      "torch.Size([8, 96000]) 10\n",
      "torch.Size([8, 96000]) 11\n",
      "torch.Size([8, 96000]) 12\n",
      "torch.Size([8, 96000]) 13\n",
      "torch.Size([8, 96000]) 14\n",
      "torch.Size([8, 96000]) 15\n",
      "torch.Size([8, 96000]) 16\n",
      "torch.Size([8, 96000]) 17\n",
      "torch.Size([8, 96000]) 18\n",
      "torch.Size([8, 96000]) 19\n",
      "torch.Size([8, 96000]) 20\n",
      "torch.Size([8, 96000]) 21\n",
      "torch.Size([8, 96000]) 22\n",
      "torch.Size([8, 96000]) 23\n",
      "torch.Size([8, 96000]) 24\n",
      "torch.Size([8, 96000]) 25\n",
      "torch.Size([8, 96000]) 26\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for index, i in enumerate(data_loader):\n",
    "    print(i[0].shape, index)\n",
    "    if index < 32:\n",
    "        continue\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
