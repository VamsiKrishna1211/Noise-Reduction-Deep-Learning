{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torchaudio as ta\n",
    "ta.set_audio_backend(\"sox_io\")\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd.profiler as profiler\n",
    "from torch_lr_finder import LRFinder\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "import glob\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from python_files.Noise_Reduction_Datagen_fp16 import Signal_Synthesis_DataGen\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import gc\n",
    "\n",
    "# from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *\n",
    "from fastai.data.core import DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float16)\n",
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noise from saved file\n",
      "Loading nums from npy file\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "noise_dir = \"./dataset/UrbanSound8K-Resampled/audio/\"\n",
    "signal_dir = \"./dataset/cv-corpus-5.1-2020-06-22-Resampled/en/clips/\"\n",
    "signal_nums_save = \"./dataset_loader_files/signal_paths_nums_save.npy\"\n",
    "num_noise_samples=100\n",
    "num_signal_samples = 100\n",
    "noise_save_path = \"./dataset_loader_files/noise_paths_resampled_save.npy\"\n",
    "n_fft=1024\n",
    "win_length=n_fft\n",
    "hop_len=n_fft//4\n",
    "create_specgram = False\n",
    "perform_stft = False\n",
    "default_sr = 16000\n",
    "sec = 2\n",
    "augment=True\n",
    "device_datagen = \"cpu\"\n",
    "\n",
    "signal_synthesis_dataset = Signal_Synthesis_DataGen(noise_dir, signal_dir, \\\n",
    "                signal_nums_save=signal_nums_save, num_noise_samples=num_noise_samples, \\\n",
    "                num_signal_samples=num_signal_samples, noise_path_save=noise_save_path, \\\n",
    "                 n_fft=n_fft, win_length=win_length, hop_len=hop_len, create_specgram=create_specgram, \\\n",
    "                 perform_stft=perform_stft, normalize=True, default_sr=default_sr, sec=sec, epsilon=1e-5, augment=False, device=device_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "shuffle = True\n",
    "num_workers = 8\n",
    "pin_memory = False\n",
    "# data_loader = DataLoader(signal_synthesis_dataset, batch_size=BATCH_SIZE, shuffle=shuffle, num_workers=num_workers)\n",
    "# data_loader = DataLoader(signal_synthesis_dataset, batch_size=BATCH_SIZE, shuffle=shuffle, num_workers=num_workers, pin_memory=pin_memory)\n",
    "# data_loader.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders.from_dsets(signal_synthesis_dataset, bs=BATCH_SIZE, num_workers=num_workers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_synthesis_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # data_loader_iter = iter(data_loader)\n",
    "# for index, i in enumerate(data_loader):\n",
    "# #     i = next(data_loader)\n",
    "#     if index < 32-1:\n",
    "#         pass\n",
    "#     else:\n",
    "#         break\n",
    "#     print(i[1].shape,i[0].min(), i[0].max(), i[0].dtype, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# stft_sig = torch.stft(i[0], n_fft=n_fft, hop_length=hop_len, win_length=win_length)\n",
    "# istft_sig = torch.istft(stft_sig, n_fft=n_fft, hop_length=hop_len, win_length=win_length)\n",
    "# i[1].max()\n",
    "\n",
    "# nan_sig = signal_synthesis_dataset.__getitem__(119)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# nan_sig[0].max(), nan_sig[1].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# stft_sig.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# stft_sig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# istft_sig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def normalize(tensor):\n",
    "#     tensor_minusmean = tensor - tensor.min()\n",
    "#     return tensor_minusmean/tensor_minusmean.abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# aud = i[0][0]\n",
    "\n",
    "# aud.dtype\n",
    "\n",
    "# aud.max(), aud.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# x = aud.t().to(\"cpu\").numpy()\n",
    "# ipd.Audio(x, rate=default_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# sig1 = i[0].unsqueeze(dim=1)\n",
    "# sig2 = i[0].unsqueeze(dim=1)\n",
    "# stacked_sig = torch.cat((sig1, sig2), dim=1)\n",
    "\n",
    "# sig2 = i[0].unsqueeze(dim=1)\n",
    "# sig2.shape\n",
    "\n",
    "# torch.sum(stacked_sig, dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# np.floor(((default_sr*sec) - (win_length - 1) - 1)/ hop_len + 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# n_fft // 2 + 1\n",
    "\n",
    "# n_fft // 2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# stft_sig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstantLayerNormalization(nn.Module):\n",
    "    def __init__(self, in_shape, out_shape):\n",
    "        self.in_shape = in_shape\n",
    "        self.out_shape = out_shape\n",
    "        \n",
    "        self.epsilon = 1e-7\n",
    "        self.gamma = None\n",
    "        self.beta = None\n",
    "        \n",
    "        super(InstantLayerNormalization, self).__init__()\n",
    "        \n",
    "        self.gamma = torch.ones(out_shape)\n",
    "        self.gamma = nn.Parameter(self.gamma)\n",
    "        \n",
    "        self.beta = torch.zeros(out_shape)\n",
    "        self.beta = nn.Parameter(self.beta)\n",
    "        \n",
    "    def forward(self, inps):\n",
    "        mean = inps.mean(-1, keepdim=True)\n",
    "        variance = torch.mean(torch.square(inps - mean), dim=-1, keepdim=True)\n",
    "        std = torch.sqrt(variance + self.epsilon)\n",
    "        \n",
    "        outs = (inps - mean) / std\n",
    "        print(outs.shape, self.gamma.shape)\n",
    "        outs = outs * self.gamma\n",
    "        outs = outs + self.beta\n",
    "        \n",
    "        return outs\n",
    "    \n",
    "class Multiply():\n",
    "    def __init__(self):\n",
    "        super(Multiply, self).__init__()\n",
    "    \n",
    "    def forward(self, ten1, ten2):\n",
    "        mul_out = torch.mul(ten1, ten2)\n",
    "        return mul_out\n",
    "\n",
    "class NoiseReducer(nn.Module):\n",
    "    def __init__(self, default_sr, n_fft, win_length, hop_len, sec, dropout=0.5, batch_first=True, stride=2, normalized=False, bidir=False):\n",
    "        \n",
    "        self.default_sr = default_sr\n",
    "        self.n_fft = n_fft\n",
    "        self.win_length = win_length\n",
    "        self.hop_len = hop_len\n",
    "        self.sec = sec\n",
    "        self.normalized = normalized\n",
    "        \n",
    "        self.conv_filters = 512\n",
    "        \n",
    "        # Universal LSTM Units\n",
    "        self.batch_first = True\n",
    "        self.dropout = 0.25\n",
    "        self.bidir = bidir\n",
    "        self.lstm_prelu_ins = int(np.floor(((default_sr*sec) - (win_length - 1) - 1)/ hop_len + 5))\n",
    "        \n",
    "        # LSTM 1 UNITS\n",
    "        self.rnn1_dims = n_fft // 2 + 1\n",
    "        self.hidden_size_1 = 256\n",
    "        self.num_layers = 2\n",
    "       \n",
    "        \n",
    "        # LSTM 2 UNITS\n",
    "        self.rnn2_dims = self.conv_filters\n",
    "        self.hidden_size_2 = self.hidden_size_1\n",
    "        \n",
    "        # Conv1d Layer Units\n",
    "        self.conv1_in = 1\n",
    "        self.conv1_out = self.conv_filters\n",
    "        \n",
    "        \n",
    "        \n",
    "        # InstanceNorm Layer Units\n",
    "        self.instance1_in = self.rnn1_dims\n",
    "        self.instance2_in = self.conv1_out\n",
    "        \n",
    "        # Dense1 Layer Units\n",
    "        self.dense1_in = self.hidden_size_1\n",
    "        self.dense1_out = self.rnn1_dims #int(np.floor(((default_sr*sec) - (win_length - 1) - 1)/ hop_len + 5))#3))\n",
    "        \n",
    "        # Dense2 Layer Units\n",
    "        self.dense2_in = self.hidden_size_2\n",
    "        self.dense2_out = self.conv1_out\n",
    "        \n",
    "        # Dense3 Layer Units\n",
    "        self.dense3_in = self.hidden_size_1\n",
    "        self.dense3_out = self.rnn1_dims\n",
    "        \n",
    "        # Conv2d Layer Units\n",
    "        self.conv2_in = self.dense2_out\n",
    "        self.conv2_out = self.conv_filters\n",
    "        \n",
    "\n",
    "        super(NoiseReducer, self).__init__()\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size=self.rnn1_dims, hidden_size=self.hidden_size_1, num_layers=self.num_layers, batch_first=self.batch_first, dropout=self.dropout, bidirectional=self.bidir)\n",
    "        self.lstm3 = nn.LSTM(input_size=self.rnn1_dims, hidden_size=self.hidden_size_1, num_layers=self.num_layers, batch_first=self.batch_first, dropout=self.dropout, bidirectional=self.bidir)\n",
    "#         self.lstm1_1 = nn.LSTMCell(input_size=self.rnn1_dims, hidden_size==self.hidden_size_1, )\n",
    "        \n",
    "        print(self.rnn2_dims)\n",
    "        self.lstm2 = nn.LSTM(input_size=self.rnn2_dims, hidden_size=self.hidden_size_2, num_layers=self.num_layers*2, batch_first=self.batch_first, dropout=self.dropout, bidirectional=self.bidir)\n",
    "        \n",
    "        \n",
    "        self.instancenorm1 = nn.InstanceNorm1d(self.rnn1_dims)\n",
    "        self.instancenorm2 = nn.InstanceNorm1d(self.rnn2_dims)\n",
    "        self.instancenorm3 = nn.InstanceNorm1d(self.rnn1_dims)\n",
    "        \n",
    "        self.dense1 = nn.Linear(self.dense1_in, self.dense1_out)\n",
    "        self.dense2 = nn.Linear(self.dense2_in, self.dense2_out)\n",
    "        self.dense3 = nn.Linear(self.dense3_in, self.dense3_out)\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(self.conv1_in, self.conv1_out, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(self.conv2_in, self.conv2_out, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.prelu_conv1 = nn.PReLU(self.conv1_out)\n",
    "        self.prelu_conv2 = nn.PReLU(self.conv2_out)\n",
    "        \n",
    "        self.prelu_lstm1 = nn.PReLU(self.lstm_prelu_ins)\n",
    "        self.prelu_lstm3 = nn.PReLU(self.lstm_prelu_ins)\n",
    "        self.prelu_lstm2 = nn.PReLU(self.hidden_size_2)\n",
    "        \n",
    "    @torch.jit.export\n",
    "    def stft_layer(self, sig):\n",
    "        \n",
    "        sig_stft = torch.stft(sig, n_fft=self.n_fft, hop_length=self.hop_len, win_length=self.win_length)\n",
    "        \n",
    "        sig_cplx = torch.view_as_complex(sig_stft)\n",
    "        mag = sig_cplx.abs().permute(0, 2, 1)\n",
    "        angle = sig_cplx.angle().permute(0, 2, 1)\n",
    "\n",
    "#         mag = sig_stft[:,:,:,0].permute(0, 2, 1)\n",
    "#         angle = sig_stft[:,:,:,1].permute(0, 2, 1)\n",
    "        \n",
    "        return [mag, angle]\n",
    "    \n",
    "    @torch.jit.export\n",
    "    def istft_layer(self, mag, angle):\n",
    "        mag = mag.permute(0, 2, 1)\n",
    "        angle = angle.permute(0, 2, 1)\n",
    "        mag = torch.unsqueeze(mag, dim=-1)\n",
    "        angle = torch.unsqueeze(angle, dim=-1)\n",
    "        pre_stft = torch.cat((mag, angle), dim=-1)\n",
    "        stft_sig = torch.istft(pre_stft, n_fft=self.n_fft, win_length=self.win_length, hop_length=self.hop_len)\n",
    "        \n",
    "        return stft_sig\n",
    "    \n",
    "    @torch.cuda.amp.autocast()\n",
    "    def forward(self, inp_tensor):\n",
    "        \n",
    "        mag, angle = self.stft_layer(inp_tensor)\n",
    "        mag_norm = self.instancenorm1(mag)\n",
    "        angle_norm = self.instancenorm3(angle)\n",
    "        \n",
    "        x_mag, hidden_states_mag = self.lstm1(mag_norm)\n",
    "        x_angle, hidden_states_angle = self.lstm3(angle_norm)\n",
    "\n",
    "        mask_mag = F.relu(self.dense1(x_mag))\n",
    "        estimated_mag = torch.mul(mag, mask_mag)\n",
    "        \n",
    "        mask_angle = F.relu(self.dense3(x_angle))\n",
    "        estimated_angle = torch.mul(angle, mask_angle)\n",
    "        \n",
    "        signal = self.istft_layer(estimated_mag, estimated_angle)\n",
    "        signal = signal.unsqueeze(dim=1)\n",
    "\n",
    "        feature_rep = self.conv1(signal)\n",
    "        feature_rep = self.prelu_conv2(feature_rep)\n",
    "        \n",
    "        feature_norm = self.instancenorm2(feature_rep)\n",
    "        feature_norm = feature_norm.permute(0, 2, 1)\n",
    "        x, hidden_states = self.lstm2(feature_norm)\n",
    "        mask = self.dense2(x)\n",
    "        feature_mask = F.relu(mask)\n",
    "        feature_mask = feature_mask.permute(0, 2, 1)\n",
    "\n",
    "        estimate_feat = torch.mul(feature_rep, feature_mask)\n",
    "        \n",
    "        estimate_frames = (self.conv2(estimate_feat))\n",
    "        estimate_frames = self.prelu_conv2(estimate_frames)\n",
    "        estimate_sig = torch.sum(estimate_frames, dim=1)\n",
    "        \n",
    "        return estimate_sig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Negative_SNR_Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Negative_SNR_Loss, self).__init__()\n",
    "    \n",
    "    def forward(self, sig_pred, sig_true):\n",
    "        \n",
    "        sig_true_sq = torch.square(sig_true)\n",
    "        sig_pred_sq = torch.square(sig_true - sig_pred)\n",
    "\n",
    "        sig_true_mean = torch.mean(sig_true_sq)\n",
    "        sig_pred_mean = torch.mean(sig_pred_sq)\n",
    "\n",
    "        snr = sig_true_mean / sig_pred_mean + 1e-7\n",
    "        loss = -1*torch.log10(snr)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Primary model\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "use_scripted_model = False\n",
    "w_decay = 1e-4\n",
    "\n",
    "if not use_scripted_model:\n",
    "    print(\"Using Primary model\")\n",
    "    model = NoiseReducer(default_sr=default_sr, n_fft=n_fft, win_length=win_length, hop_len=hop_len, sec=sec).to(device)\n",
    "    model.to(device)\n",
    "else:\n",
    "    print(\"Using Scripted Model\")\n",
    "    model = scripted_model\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0)\n",
    "criterion = nn.MSELoss(reduction=\"mean\")#Negative_SNR_Loss()\n",
    "n_epochs=100\n",
    "\n",
    "\n",
    "model.train()\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, loss_func=criterion, model_dir=\"./Model_saves/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.0007585775572806596, lr_steep=0.00010964782268274575)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake_inputs = torch.randn(BATCH_SIZE, int(default_sr*sec)).type(torch.float32).to(device)\n",
    "# outs = model(fake_inputs)\n",
    "# outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='653' class='' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      52.24% [653/1250 1:06:18<1:00:37 0.0075]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fine_tune(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"./Model_saves/Pytorch_model_2_save_LSTM_512_filters.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    \n",
    "    loop = tqdm(enumerate(data_loader), leave=True, total=len(data_loader))\n",
    "    train_loss = np.zeros((len(data_loader)))\n",
    "    loop.set_description(f\"Epoch: [ {epoch}/{n_epochs} ]\\t\")\n",
    "\n",
    "    \n",
    "    for index, (data, target) in loop:\n",
    "        \n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        for group in optimizer.param_groups:\n",
    "            for param in group[\"params\"]:\n",
    "                param.data = param.data.add(-w_decay * group[\"lr\"], param.data)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "#         output = model(data)\n",
    "#         loss = criterion(output, target)\n",
    "        \n",
    "#         loss.backward()\n",
    "#         for group in optimizer.param_groups:\n",
    "#             for param in group[\"params\"]:\n",
    "#                 param.data = param.data.add(-w_decay * group[\"lr\"], param.data)\n",
    "#         optimizer.step()\n",
    "\n",
    "        train_loss[index] = loss.item()\n",
    "        if np.isnan(loss.item()) or np.isnan(np.sum(train_loss)/index+1e-5):\n",
    "            print(f\"Data shape = {data.shape}\\nTarget Shape = {target.shape}, \\nindex = {index}\")\n",
    "        disp_loss = np.sum(train_loss)/index+1e-5\n",
    "        loop.set_postfix(loss = disp_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.closure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./Model_saves/Pytorch_model_2_save_LSTM_512_filters.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_add_sig, main_sig = signal_synthesis_dataset.__getitem__(1000)\n",
    "noise_add_sig = torch.unsqueeze(noise_add_sig, dim=0).to(device)\n",
    "main_sig = torch.unsqueeze(main_sig, dim=0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    outs = model(noise_add_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_loss = torch.nn.CosineSimilarity()(main_sig, outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sim_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = outs[0].t().to(\"cpu\").numpy()\n",
    "ipd.Audio(x, rate=default_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = noise_add_sig[0].t().to(\"cpu\").numpy()\n",
    "ipd.Audio(x, rate=default_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = main_sig[0].t().to(\"cpu\").numpy()\n",
    "ipd.Audio(x, rate=default_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_add_sig.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
